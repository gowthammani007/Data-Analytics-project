{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation for CHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import glob\n",
    "import re\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from scipy.cluster.hierarchy import ward, dendrogram, fcluster\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import networkx as nx\n",
    "from ast import literal_eval\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 6\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from pmdarima.arima import auto_arima\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_dataframe(folder_path):\n",
    "    \"\"\"\n",
    "    Read all the csv files in the given folder and concatanate them into a single dataframe\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    csv_files = glob.glob(folder_path)\n",
    "\n",
    "    for filename in csv_files:\n",
    "        df = pd.read_csv(filename)\n",
    "        df_list.append(df)\n",
    "    \n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path all inpatient csv's\n",
    "inp_folder_path = \"data/INPT 2015-2023 Q1-Q3/*.csv\"\n",
    "# folder path all emergency csv's\n",
    "ed_folder_path = \"data/ED 2015-2023Q1-Q3/*.csv\"\n",
    "\n",
    "inp_df = csv_to_dataframe(inp_folder_path)\n",
    "ed_df = csv_to_dataframe(ed_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the dimensions\n",
    "print(f\"inpatient data: {inp_df.shape}\")\n",
    "print(f\"outpatient/ed data: {ed_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICD-10 CM codes for CHD\n",
    "chd_icd_10_list = [\"I25\", \"I25.1\", \"I25.10\", \"I25.11\", \"I25.110\", \"I25.111\", \"I25.112\", \"I25.118\", \"I25.119\", \n",
    "                   \"I25.2\", \"I25.3\", \"I25.4\", \"I25.41\", \"I25.42\", \"I25.5\", \"I25.6\", \"I25.7\", \"I25.70\", \"I25.700\", \n",
    "                   \"I25.701\", \"I25.702\", \"I25.708\", \"I25.709\", \"I25.71\", \"I25.710\", \"I25.711\", \"I25.712\", \"I25.718\", \n",
    "                   \"I25.719\", \"I25.72\", \"I25.720\", \"I25.721\", \"I25.722\", \"I25.728\", \"I25.729\", \"I25.73\", \"I25.730\", \"I25.731\", \n",
    "                   \"I25.732\", \"I25.738\", \"I25.739\", \"I25.75\", \"I25.750\", \"I25.751\", \"I25.752\", \"I25.758\", \"I25.759\", \"I25.76\", \n",
    "                   \"I25.760\", \"I25.761\", \"I25.762\", \"I25.768\", \"I25.769\", \"I25.79\", \"I25.790\", \"I25.791\", \"I25.792\", \"I25.798\", \n",
    "                   \"I25.799\", \"I25.8\", \"I25.81\", \"I25.810\", \"I25.811\", \"I25.812\", \"I25.82\", \"I25.83\", \"I25.84\", \"I25.85\", \"I25.89\", \"I25.9\"]\n",
    "\n",
    "# HD MSDRG\"s dictionary\n",
    "hd_msdrg_dic = {\n",
    "    231: \"CORONARY BYPASS WITH PTCA WITH MCC\", \n",
    "    232: \"CORONARY BYPASS WITH PTCA WITHOUT MCC\",\n",
    "    233: \"CORONARY BYPASS WITH CARDIAC CATHETERIZATION WITH MCC\",\n",
    "    234: \"CORONARY BYPASS WITH CARDIAC CATHETERIZATION WITHOUT MCC\",\n",
    "    235: \"CORONARY BYPASS WITHOUT CARDIAC CATHETERIZATION WITH MCC\",\n",
    "    236: \"CORONARY BYPASS WITHOUT CARDIAC CATHETERIZATION WITHOUT MCC\",\n",
    "    246: \"PERCUTANEOUS CARDIOVASCULAR PROCEDURES WITH DRUG-ELUTING STENT WITH MCC OR 4+ ARTERIES OR STENTS\",\n",
    "    247: \"PERCUTANEOUS CARDIOVASCULAR PROCEDURES WITH DRUG-ELUTING STENT WITHOUT MCC\",\n",
    "    248: \"PERCUTANEOUS CARDIOVASCULAR PROCEDURES WITH NON-DRUG-ELUTING STENT WITH MCC OR 4+ ARTERIES OR STENTS\",\n",
    "    249: \"PERCUTANEOUS CARDIOVASCULAR PROCEDURES WITH NON-DRUG-ELUTING STENT WITHOUT MCC\",\n",
    "    250: \"PERCUTANEOUS CARDIOVASCULAR PROCEDURES WITHOUT CORONARY ARTERY STENT WITH MCC\",\n",
    "    251: \"PERCUTANEOUS CARDIOVASCULAR PROCEDURES WITHOUT CORONARY ARTERY STENT WITHOUT MCC\",\n",
    "    273: \"PERCUTANEOUS INTRACARDIAC PROCEDURES WITH MCC\",\n",
    "    274: \"PERCUTANEOUS INTRACARDIAC PROCEDURES WITHOUT MCC\",\n",
    "    319: \"OTHER ENDOVASCULAR CARDIAC VALVE PROCEDURES WITH MCC\",\n",
    "    320: \"OTHER ENDOVASCULAR CARDIAC VALVE PROCEDURES WITHOUT MCC\",\n",
    "    216: \"CARDIAC VALVE AND OTHER MAJOR CARDIOTHORACIC PROCEDURES WITH CARDIAC CATHETERIZATION WITH MCC\",\n",
    "    217: \"CARDIAC VALVE AND OTHER MAJOR CARDIOTHORACIC PROCEDURES WITH CARDIAC CATHETERIZATION WITH CC\",\n",
    "    218: \"CARDIAC VALVE AND OTHER MAJOR CARDIOTHORACIC PROCEDURES WITH CARDIAC CATHETERIZATION WITHOUT CC/MCC\",\n",
    "    219: \"CARDIAC VALVE AND OTHER MAJOR CARDIOTHORACIC PROCEDURES WITHOUT CARDIAC CATHETERIZATION WITH MCC\",\n",
    "    220: \"CARDIAC VALVE AND OTHER MAJOR CARDIOTHORACIC PROCEDURES WITHOUT CARDIAC CATHETERIZATION WITH CC\",\n",
    "    221: \"CARDIAC VALVE AND OTHER MAJOR CARDIOTHORACIC PROCEDURES WITHOUT CARDIAC CATHETERIZATION WITHOUT CC/MCC\",\n",
    "    311: \"ANGINA PECTORIS\",\n",
    "    302: \"ATHEROSCLEROSIS WITH MCC\",\n",
    "    303: \"ATHEROSCLEROSIS WITHOUT MCC\",\n",
    "    304: \"HYPERTENSION WITH MCC\",\n",
    "    305: \"HYPERTENSION WITHOUT MCC\",\n",
    "    299: \"PERIPHERAL VASCULAR DISORDERS WITH MCC\",\n",
    "    300: \"PERIPHERAL VASCULAR DISORDERS WITH CC\",\n",
    "    301: \"PERIPHERAL VASCULAR DISORDERS WITHOUT CC/MCC\",\n",
    "    291: \"HEART FAILURE AND SHOCK WITH MCC\",\n",
    "    292: \"HEART FAILURE AND SHOCK WITH CC\",\n",
    "    293: \"HEART FAILURE AND SHOCK WITHOUT CC/MCC\",\n",
    "    280: \"ACUTE MYOCARDIAL INFARCTION, DISCHARGED ALIVE WITH MCC\",\n",
    "    281: \"ACUTE MYOCARDIAL INFARCTION, DISCHARGED ALIVE WITH CC\",\n",
    "    282: \"ACUTE MYOCARDIAL INFARCTION, DISCHARGED ALIVE WITHOUT CC/MCC\",\n",
    "    283: \"ACUTE MYOCARDIAL INFARCTION, EXPIRED WITH MCC\",\n",
    "    284: \"ACUTE MYOCARDIAL INFARCTION, EXPIRED WITH CC\",\n",
    "    285: \"ACUTE MYOCARDIAL INFARCTION, EXPIRED WITHOUT CC/MCC MS\"\n",
    "}\n",
    "\n",
    "# county dictionary - according to the AHCA format\n",
    "county_dict = {\n",
    "    1: \"Alachua\",\n",
    "    2: \"Baker\",\n",
    "    3: \"Bay\",\n",
    "    4: \"Bradford\",\n",
    "    5: \"Brevard\",\n",
    "    6: \"Broward\",\n",
    "    7: \"Calhoun\",\n",
    "    8: \"Charlotte\",\n",
    "    9: \"Citrus\",\n",
    "    10: \"Clay\",\n",
    "    11: \"Collier\",\n",
    "    12: \"Columbia\",\n",
    "    13: \"Miami-Dade\",\n",
    "    14: \"Desoto\",\n",
    "    15: \"Dixie\",\n",
    "    16: \"Duval\",\n",
    "    17: \"Escambia\",\n",
    "    18: \"Flagler\",\n",
    "    19: \"Franklin\",\n",
    "    20: \"Gadsden\",\n",
    "    21: \"Gilchrist\",\n",
    "    22: \"Glades\",\n",
    "    23: \"Gulf\",\n",
    "    24: \"Hamilton\",\n",
    "    25: \"Hardee\",\n",
    "    26: \"Hendry\",\n",
    "    27: \"Hernando\",\n",
    "    28: \"Highlands\",\n",
    "    29: \"Hillsborough\",\n",
    "    30: \"Holmes\",\n",
    "    31: \"Indian River\",\n",
    "    32: \"Jackson\",\n",
    "    33: \"Jefferson\",\n",
    "    34: \"Lafayette\",\n",
    "    35: \"Lake\",\n",
    "    36: \"Lee\",\n",
    "    37: \"Leon\",\n",
    "    38: \"Levy\",\n",
    "    39: \"Liberty\",\n",
    "    40: \"Madison\",\n",
    "    41: \"Manatee\",\n",
    "    42: \"Marion\",\n",
    "    43: \"Martin\",\n",
    "    44: \"Monroe\",\n",
    "    45: \"Nassau\",\n",
    "    46: \"Okaloosa\",\n",
    "    47: \"Okeechobee\",\n",
    "    48: \"Orange\",\n",
    "    49: \"Osceola\",\n",
    "    50: \"Palm Beach\",\n",
    "    51: \"Pasco\",\n",
    "    52: \"Pinellas\",\n",
    "    53: \"Polk\",\n",
    "    54: \"Putnam\",\n",
    "    55: \"Saint Johns\",\n",
    "    56: \"Saint Lucie\",\n",
    "    57: \"Santa Rosa\",\n",
    "    58: \"Sarasota\",\n",
    "    59: \"Seminole\",\n",
    "    60: \"Sumter\",\n",
    "    61: \"Suwannee\",\n",
    "    62: \"Taylor\",\n",
    "    63: \"Union\",\n",
    "    64: \"Volusia\",\n",
    "    65: \"Wakulla\",\n",
    "    66: \"Walton\",\n",
    "    67: \"Washington\",\n",
    "    99: \"Unknown\"\n",
    "}\n",
    "\n",
    "chd_msdrg_list = [int(key) for key in hd_msdrg_dic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter patients treated for CHD in inpatient data using MScodes\n",
    "chd_inp_df = inp_df[inp_df[\"MSDRG\"].isin(chd_msdrg_list[:14])]\n",
    "print(f\"inpatient CHD data: {chd_inp_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter patients diagnosed with CHD in outpatient data using ICD-10 CM codes\n",
    "prindiag_col = ed_df[[\"PRINDIAG\"]]\n",
    "othdiag_cols = ed_df.filter(regex=\"^OTHDIAG\\d+$\")\n",
    "selected_cols = pd.concat([prindiag_col, othdiag_cols], axis=1)\n",
    "\n",
    "def check_icd_codes_in_rows(row):\n",
    "    \"\"\"\n",
    "    Check for any of the given ICD-10 CM codes in the columns of each row\n",
    "    \"\"\"\n",
    "    return any(code in row.values for code in chd_icd_10_list)\n",
    "\n",
    "selected_rows = selected_cols.apply(check_icd_codes_in_rows, axis=1)\n",
    "chd_ed_df = ed_df[selected_rows]\n",
    "\n",
    "print(f\"ED CHD data: {chd_ed_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the final merged CHD dataframes into csv\"s\n",
    "chd_inp_df.to_csv(\"data/CHD_INPT.csv\")\n",
    "chd_ed_df.to_csv(\"data/CHD_ED.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis for CHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the inpatient and outpatient CSV\"s for CHD\n",
    "chd_inp_df = pd.read_csv(\"data/CHD_INPT.csv\")\n",
    "chd_ed_df = pd.read_csv(\"data/CHD_ED.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "inp_drop_columns = [\"FACLNBR\", \"MCARE_NBR\", \"PRO_CODE\", \"MOD_CODE\", \"FAC_REGION\", \n",
    "            \"TYPE_SERV\", \"CONDTN\", \"EDHR_ARR\", \"ADM_TIME\", \"DIS_TIME\", \n",
    "            \"PAYER\", \"ZIPCODE\", \"PRINDIAG\", \"POA_PRIN_DIAG\", \"PRINPROC\", \n",
    "            \"WEEKDAY\", \"DAYSPROC\", \"ICUCHGS\", \"CCUCHGS\", \"PHARMCHGS\", \n",
    "            \"MEDCHGS\", \"ONCOCHGS\", \"LABCHGS\", \"RADCHGS\", \"OPRMCHGS\", \n",
    "            \"ANESCHGS\", \"RESPCHGS\", \"PHYTHCHGS\", \"OCCUPCHGS\", \"SPEECHGS\", \n",
    "            \"ERCHGS\", \"CARDIOCHGS\", \"TRAUMACHGS\", \"RECOVCHGS\", \"LABORCHGS\", \n",
    "            \"OBSERCHGS\", \"BEHAVCHGS\", \"OTHERCHGS\", \"TCHGS\", \"CERT_DATE\", \"ADMITDIAG\", \n",
    "            \"ADM_PRIOR\", \"PAYER_NAME\", \"FACL_NAME\", \"ROOMCHGS\", \"FAC_NAME\", \"Unnamed: 0\"]\n",
    "\n",
    "for i in range(30):\n",
    "    inp_drop_columns.append(f\"OTHDIAG{i+1}\")\n",
    "    inp_drop_columns.append(f\"POA{i+1}\")\n",
    "    inp_drop_columns.append(f\"OTHPROC{i+1}\")\n",
    "    inp_drop_columns.append(f\"DAYS_PROC{i+1}\")\n",
    "for i in range(3):\n",
    "    inp_drop_columns.append(f\"ECMORB{i+1}\")\n",
    "    inp_drop_columns.append(f\"POA_ECMORB{i+1}\")\n",
    "    inp_drop_columns.append(f\"NUR{i+1}CHGS\")\n",
    "\n",
    "ed_drop_columns = [\"FACLNBR\", \"MCARE_NBR\", \"PRO_CODE\", \"FAC_REGION\", \n",
    "            \"TYPE_SERV\", \"SERV_LOC\", \"FAC_REGION\", \"WEEKDAY\", \"ZIPCODE\",\n",
    "            \"ADMSRC\", \"HR_ARRIVAL\", \"EDHR_DISCH\", \"PAYER\", \"EVALCODE1\",\n",
    "            \"EVALCODE2\", \"EVALCODE3\", \"EVALCODE4\", \"EVALCODE5\", \"PRINDIAG\", \n",
    "            \"PRINPROC\", \"PHARMCHGS\", \"MEDCHGS\", \"LABCHGS\",\"RADCHGS\", \n",
    "            \"OPRMCHGS\", \"ANESCHGS\", \"ERCHGS\", \"CARDIOCHGS\", \"TRAUMACHGS\", \n",
    "            \"RECOVCHGS\", \"OBSERCHGS\", \"GASTROCHGS\", \"LITHOCHGS\", \"OTHCHGS\", \n",
    "            \"COPD_COUNTS\", \"CERT_DATE\", \"TCHGS\", \"FACL_NAME\", \"REASON_CDE\", \"PAYER_NAME\", \"Unnamed: 0\"]\n",
    "\n",
    "for i in range(9):\n",
    "    ed_drop_columns.append(f\"OTHDIAG{i+1}\")\n",
    "for i in range(3):\n",
    "    ed_drop_columns.append(f\"ECMORB{i+1}\")\n",
    "for i in range(4):\n",
    "    ed_drop_columns.append(f\"OTHPROC{i+1}\")\n",
    "for i in range(30):\n",
    "    ed_drop_columns.append(f\"OTHCPT{i+1}\")\n",
    "\n",
    "# drop unnecessary inpatient columns\n",
    "chd_inp_df = chd_inp_df.drop(columns=inp_drop_columns, errors=\"ignore\")\n",
    "# drop unnecessary ED columns\n",
    "chd_ed_df = chd_ed_df.drop(columns=ed_drop_columns,  errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print column data types of CHD inpatient data\n",
    "print(chd_inp_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print column data types of CHD inpatient data\n",
    "print(chd_ed_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucketize age groups\n",
    "age_bins = [1, 34, 44, 54, 64, 74, 84, float(\"inf\")]\n",
    "age_labels = [\"<35\", \"35-44\", \"45-54\", \"55-64\", \"65-74\", \"75-84\", \">=85\"]\n",
    "\n",
    "chd_inp_df[\"AGE_GROUP\"] = pd.cut(chd_inp_df[\"AGE\"], bins=age_bins, labels=age_labels, include_lowest=True)\n",
    "chd_ed_df[\"AGE_GROUP\"] = pd.cut(chd_ed_df[\"AGE\"], bins=age_bins, labels=age_labels, include_lowest=True)\n",
    "\n",
    "chd_inp_df[\"AGE_GROUP\"] = chd_inp_df[\"AGE_GROUP\"].astype(\"object\")\n",
    "chd_ed_df[\"AGE_GROUP\"] = chd_ed_df[\"AGE_GROUP\"].astype(\"object\")\n",
    "\n",
    "chd_inp_df.loc[chd_inp_df[\"AGE\"] == 0, \"AGE_GROUP\"] = \"New Born(0-28 days)\"\n",
    "chd_inp_df.loc[chd_inp_df[\"AGE\"] == 777, \"AGE_GROUP\"] = \"Infant(29-364 days)\"\n",
    "chd_inp_df.loc[chd_inp_df[\"AGE\"] == 888, \"AGE_GROUP\"] = \">=85\"\n",
    "chd_inp_df.loc[chd_inp_df[\"AGE\"] > 100, \"AGE_GROUP\"] = \">=85\"\n",
    "\n",
    "chd_ed_df.loc[chd_ed_df[\"AGE\"] == 0, \"AGE_GROUP\"] = \"New Born(0-28 days)\"\n",
    "chd_ed_df.loc[chd_ed_df[\"AGE\"] == 777, \"AGE_GROUP\"] = \"Infant(29-364 days)\"\n",
    "chd_ed_df.loc[chd_ed_df[\"AGE\"] == 888, \"AGE_GROUP\"] = \">=85\"\n",
    "chd_ed_df.loc[chd_ed_df[\"AGE\"] > 100, \"AGE_GROUP\"] = \">=85\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate diagnosed and treated people into residents(FL) and tourists.\n",
    "inp_state_filter = chd_inp_df[\"PTSTATE\"] == \"FL\"\n",
    "ed_state_filter = chd_ed_df[\"PTSTATE\"] == \"FL\"\n",
    "\n",
    "chd_inp_df[\"RESIDENT_TYPE\"] = None\n",
    "chd_ed_df[\"RESIDENT_TYPE\"] = None\n",
    "\n",
    "chd_inp_df.loc[inp_state_filter, \"RESIDENT_TYPE\"] = \"Resident\"\n",
    "chd_inp_df.loc[~inp_state_filter, \"RESIDENT_TYPE\"] = \"Non Resident\"\n",
    "\n",
    "chd_ed_df.loc[ed_state_filter, \"RESIDENT_TYPE\"] = \"Resident\"\n",
    "chd_ed_df.loc[~ed_state_filter, \"RESIDENT_TYPE\"] = \"Non Resident\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter further to isolate CABG+PCI, CABG\"s and PCI\"s\n",
    "chd_inp_df[\"PROCEDURE\"] = None\n",
    "\n",
    "chd_inp_df.loc[chd_inp_df[\"MSDRG\"].isin(chd_msdrg_list[6:]), \"PROCEDURE\"] = \"PCI\"\n",
    "chd_inp_df.loc[chd_inp_df[\"MSDRG\"].isin(chd_msdrg_list[0:2]), \"PROCEDURE\"] = \"CABG + PCI\"\n",
    "chd_inp_df.loc[chd_inp_df[\"MSDRG\"].isin(chd_msdrg_list[2:7]), \"PROCEDURE\"] = \"CABG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the count of NaN's in each column of the CHD inpatient data frame\n",
    "chd_inp_df.replace(\" \", np.nan,inplace=True)\n",
    "print(chd_inp_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the count of NaN's in each column of the CHD emergency data frame\n",
    "chd_ed_df.replace(\" \", np.nan,inplace=True)\n",
    "print(chd_ed_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing null values in PTCOUNTY_NAME and FAC_COUNTY_NAME \n",
    "\n",
    "# convert fac_county into integer\n",
    "inp_mask = chd_inp_df[\"FAC_COUNTY\"].notnull()\n",
    "chd_inp_df.loc[inp_mask, \"FAC_COUNTY\"] = chd_inp_df.loc[inp_mask, \"FAC_COUNTY\"].astype(\"int\")\n",
    "\n",
    "chd_inp_df[\"FAC_COUNTY_NAME\"] = chd_inp_df[\"FAC_COUNTY\"].map(county_dict)\n",
    "chd_inp_df[\"PTCOUNTY_NAME\"] = chd_inp_df[\"PTCOUNTY\"].map(county_dict)\n",
    "chd_ed_df[\"FAC_COUNTY_NAME\"] = chd_ed_df[\"FAC_COUNTY\"].map(county_dict)\n",
    "chd_ed_df[\"PTCOUNTY_NAME\"] = chd_ed_df[\"PTCOUNTY\"].map(county_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of CHD_COUNTS againts FAC_COUNTY_NAME\n",
    "num_rows = len(county_dict.values()) // 3 + (len(county_dict.values()) % 3 > 0)\n",
    "fig, axes = plt.subplots(num_rows, 3, figsize=(18, num_rows*4)) \n",
    "axes = axes.flatten() \n",
    "\n",
    "chd_counts = chd_ed_df[\"CHD_COUNTS\"].unique()\n",
    "bin_edges = np.sort(chd_counts) - 0.5\n",
    "\n",
    "for i, county in enumerate(county_dict.values()):\n",
    "    county_data = chd_ed_df[chd_ed_df[\"FAC_COUNTY_NAME\"] == county]\n",
    "    unique_chd_counts = np.sort(county_data[\"CHD_COUNTS\"].unique())\n",
    "    \n",
    "    if unique_chd_counts.size > 0:\n",
    "        # Define bin edges to include each unique value and an extra edge for the last bin\n",
    "        bin_edges = np.append(unique_chd_counts, unique_chd_counts[-1] + 1)\n",
    "        \n",
    "        # Create the histogram with specified bins\n",
    "        sns.histplot(data=county_data, x=\"CHD_COUNTS\", bins=bin_edges, ax=axes[i], discrete=True)\n",
    "        \n",
    "        # Set title and labels for the current subplot\n",
    "        axes[i].set_title(f\"Distribution of CHD_COUNTS for Facility County: {county}\")\n",
    "        axes[i].set_xlabel(\"CHD_COUNTS\")\n",
    "        axes[i].set_ylabel(\"Frequency\")\n",
    "        axes[i].set_xticks(chd_counts)\n",
    "    else:\n",
    "        axes[i].set_title(f\"Distribution of CHD_COUNTS for Facility County: {county}\")\n",
    "        \n",
    "# hide any empty subplots\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of CHD_COUNTS againts PTCOUNTY_NAME\n",
    "num_rows = len(county_dict.values()) // 3 + (len(county_dict.values()) % 3 > 0)\n",
    "fig, axes = plt.subplots(num_rows, 3, figsize=(18, num_rows*4)) \n",
    "axes = axes.flatten() \n",
    "\n",
    "chd_counts = chd_ed_df[\"CHD_COUNTS\"].unique()\n",
    "bin_edges = np.sort(chd_counts) - 0.5\n",
    "\n",
    "for i, county in enumerate(county_dict.values()):\n",
    "    county_data = chd_ed_df[chd_ed_df[\"PTCOUNTY_NAME\"] == county]\n",
    "    unique_chd_counts = np.sort(county_data[\"CHD_COUNTS\"].unique())\n",
    "    \n",
    "    if unique_chd_counts.size > 0:\n",
    "        # Define bin edges to include each unique value and an extra edge for the last bin\n",
    "        bin_edges = np.append(unique_chd_counts, unique_chd_counts[-1] + 1)\n",
    "        \n",
    "        # Create the histogram with specified bins\n",
    "        sns.histplot(data=county_data, x=\"CHD_COUNTS\", bins=bin_edges, ax=axes[i], discrete=True)\n",
    "        \n",
    "        # Set title and labels for the current subplot\n",
    "        axes[i].set_title(f\"Distribution of CHD_COUNTS for Patient County: {county}\")\n",
    "        axes[i].set_xlabel(\"CHD_COUNTS\")\n",
    "        axes[i].set_ylabel(\"Frequency\")\n",
    "        axes[i].set_xticks(chd_counts)\n",
    "    else:\n",
    "        axes[i].set_title(f\"Distribution of CHD_COUNTS for Patient County: {county}\")\n",
    "        \n",
    "# hide any empty subplots\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the patient counties and years where the facility county is missing\n",
    "chd_inp_missing_pt_counties = chd_inp_df.loc[chd_inp_df[\"FAC_COUNTY\"].isna(), \"PTCOUNTY\"].unique()\n",
    "chd_inp_years = chd_inp_df.loc[chd_inp_df[\"FAC_COUNTY\"].isna(), \"YEAR\"].unique()\n",
    "resident_type = chd_inp_df.loc[chd_inp_df[\"FAC_COUNTY\"].isna(), \"RESIDENT_TYPE\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = chd_inp_df.groupby([\"YEAR\", \"PTCOUNTY_NAME\", \"FAC_COUNTY_NAME\", \"RESIDENT_TYPE\"]).size().reset_index(name=\"PROC_COUNT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the percentage of other patients from the same patient county that get treated in different facility counties\n",
    "max_percentage_dict = {}\n",
    "\n",
    "for county in chd_inp_missing_pt_counties:\n",
    "    records = chd_inp_df.loc[(chd_inp_df[\"PTCOUNTY\"] == county) & (chd_inp_df[\"RESIDENT_TYPE\"] == \"Resident\")]\n",
    "    if not records.empty:\n",
    "        missing = len(records[records[\"FAC_COUNTY\"].isna()])\n",
    "        records[\"FAC_COUNTY\"] = records[\"FAC_COUNTY\"] .astype(str)\n",
    "        plt.figure(figsize=(10, 6))  # You can adjust the size as needed\n",
    "        # Create a countplot with percentages\n",
    "        ax = sns.countplot(data=records, x=\"FAC_COUNTY\", order=records[\"FAC_COUNTY\"].value_counts().index)\n",
    "        \n",
    "        # Calculate the percentage for each bar\n",
    "        total = len(records)  # Total number of records for the county\n",
    "        for p in ax.patches:\n",
    "            percentage = f'{100 * p.get_height() / total:.1f}%'\n",
    "            x = p.get_x() + p.get_width() / 2\n",
    "            y = p.get_height()\n",
    "            ax.annotate(percentage, (x, y), ha='center', va='center')\n",
    "\n",
    "        value_counts = records[\"FAC_COUNTY\"].value_counts(normalize=True)\n",
    "        percentages = value_counts * 100\n",
    "        max_percentage = percentages.max()\n",
    "        max_percentage_fac_county = percentages.idxmax()\n",
    "\n",
    "        # Save the max percentage and corresponding FAC_COUNTY to the dictionary\n",
    "        max_percentage_dict[county] = {'FAC_COUNTY': int(max_percentage_fac_county), 'Percentage': max_percentage}\n",
    "        \n",
    "        # Set the title and labels\n",
    "        plt.title(f\"Percentage of patients from {county} who got treated in different counties and missing:{missing}\")\n",
    "        plt.xticks(rotation=90)  # Rotate the x-axis labels for better readability\n",
    "        plt.xlabel(\"Facility County\")\n",
    "        plt.ylabel(\"Percentage\")\n",
    "        \n",
    "        plt.tight_layout()  # Adjust layout to prevent clipping of ylabel\n",
    "        plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the percentages of those patients getting treated from different facility counties for each patient county shown above, we can observe that most of the times a single county received a large volume of patients for treatment. Therefore for the missing facility counties w can impute with the facility county with max percentage from other patients from same patient county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing missing facility counties based on the argument mentioned above.\n",
    "for county in chd_inp_missing_pt_counties:\n",
    "    if county != 99:\n",
    "        chd_inp_df.loc[(chd_inp_df[\"PTCOUNTY\"] == county) & (chd_inp_df[\"FAC_COUNTY\"].isna()), \"FAC_COUNTY\"] = max_percentage_dict[county][\"FAC_COUNTY\"]\n",
    "    else:\n",
    "        chd_inp_df.loc[(chd_inp_df[\"PTCOUNTY\"] == 99) & (chd_inp_df[\"FAC_COUNTY\"].isna()), \"FAC_COUNTY\"] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the missing facility county names from the county dictionary.\n",
    "chd_inp_df[\"FAC_COUNTY_NAME\"] = chd_inp_df[\"FAC_COUNTY\"].map(county_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the count of NaN's in each column of the CHD inpatient data frame\n",
    "chd_inp_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a time series plot to see count of treatment procedures conducted in each county by quater per year\n",
    "chd_inp_df[\"YEAR_QTR\"] = chd_inp_df[\"YEAR\"].astype(str) + \"QTR\" + chd_inp_df[\"QTR\"].astype(str)\n",
    "chd_inp_proc_agg_by_fac = chd_inp_df.groupby([\"QTR\", \"FAC_COUNTY_NAME\", \"PROCEDURE\", \"RESIDENT_TYPE\"]).size().reset_index(name=\"PROC_COUNT\")\n",
    "\n",
    "treatments = [\"PCI\", \"CABG\", \"CABG + PCI\"]\n",
    "palette = sns.color_palette(\"husl\", len(treatments))\n",
    "treatment_colors = dict(zip(treatments, palette))\n",
    "\n",
    "for county in county_dict.values():\n",
    "    county_data = chd_inp_proc_agg_by_fac[((chd_inp_proc_agg_by_fac[\"FAC_COUNTY_NAME\"] == county) & (chd_inp_proc_agg_by_fac[\"RESIDENT_TYPE\"] == \"Resident\"))]\n",
    "    if county_data.size > 0:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.lineplot(data=county_data, x=\"YEAR\", y=\"PROC_COUNT\", hue=\"PROCEDURE\", marker=\"o\", palette=treatment_colors)\n",
    "\n",
    "        plt.title(f\"Procedure counts by year & qtr for {county}\")\n",
    "        plt.xlabel(\"year_qtr\")\n",
    "        plt.ylabel(\"count\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend(title=\"Procedure\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No data available for {county}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the population by county csv file\n",
    "usecols = [\"County\"]\n",
    "for i in range(2015, 2024):\n",
    "    usecols.append(str(i))\n",
    "\n",
    "pop_by_county = pd.read_csv(\"data/PopByCounty.csv\", usecols=usecols)\n",
    "\n",
    "pop_by_county_dics = {}\n",
    "for i, row in pop_by_county.iterrows():\n",
    "    county = row[\"County\"]\n",
    "    county_data = {year: row[year] for year in usecols if year != \"County\"}\n",
    "    pop_by_county_dics[county] = county_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt the dataframe\n",
    "pop_by_county_melt = melted_df = pd.melt(pop_by_county, id_vars=['County'], var_name='Year', value_name='Population')\n",
    "pop_by_county_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove newborn records - since this is an exceptional scenario, we are ignoring this from our study for simplicity\n",
    "chd_inp_special_df = chd_inp_df[chd_inp_df[\"AGE_GROUP\"].isin([\"New Born(0-28 days)\", \"<35\"])]\n",
    "chd_ed_special_df = chd_ed_df[chd_ed_df[\"AGE_GROUP\"].isin([\"New Born(0-28 days)\", \"<35\"])]\n",
    "chd_inp_df = chd_inp_df[~(chd_inp_df[\"AGE_GROUP\"].isin([\"New Born(0-28 days)\", \"<35\"]))]\n",
    "chd_ed_df = chd_ed_df[~(chd_ed_df[\"AGE_GROUP\"].isin([\"New Born(0-28 days)\", \"<35\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column concatanating YEAR and QTR\n",
    "chd_ed_df[\"YEAR_QTR\"] = chd_ed_df[\"YEAR\"].astype(str) + \"QTR\" + chd_ed_df[\"QTR\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a time series plot to show the county of patients diagnosed in counties by year.\n",
    "chd_inp_proc_agg_by_pt = chd_inp_df.groupby([\"YEAR\", \"PTCOUNTY_NAME\", \"PROCEDURE\", \"RESIDENT_TYPE\"]).size().reset_index(name=\"PROC_COUNT\")\n",
    "chd_ed_diag_agg_by_pt = chd_ed_df.groupby([\"YEAR\", \"PTCOUNTY_NAME\", \"RESIDENT_TYPE\"]).size().reset_index(name=\"DIAG_COUNT\")\n",
    "\n",
    "for county in county_dict.values():\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(20, 15)) \n",
    "\n",
    "    county_diag_data = chd_ed_diag_agg_by_pt[(chd_ed_diag_agg_by_pt[\"PTCOUNTY_NAME\"] == county) & (chd_ed_diag_agg_by_pt[\"RESIDENT_TYPE\"] == \"Resident\")]\n",
    "    county_pop = pop_by_county_melt[pop_by_county_melt[\"County\"] == county]\n",
    "\n",
    "    sns.lineplot(data=county_pop, x=\"Year\", y=\"Population\", ax=axes[0], marker=\"o\")\n",
    "    axes[0].set_title(f\"Population in {county}\")\n",
    "    axes[0].set_xlabel(\"Year\")\n",
    "    axes[0].set_ylabel(\"Diagnosis Count\")\n",
    "    \n",
    "    if county_diag_data.size > 0:    \n",
    "        sns.lineplot(data=county_diag_data, x=\"YEAR\", y=\"DIAG_COUNT\", ax=axes[1], marker=\"o\")\n",
    "        axes[1].set_title(f\"Diagnosis Counts for {county}\")\n",
    "        axes[1].set_xlabel(\"Year\")\n",
    "        axes[1].set_ylabel(\"Diagnosis Count\")\n",
    "\n",
    "        county_proc_data = chd_inp_proc_agg_by_pt[(chd_inp_proc_agg_by_pt[\"PTCOUNTY_NAME\"] == county) & (chd_inp_proc_agg_by_pt[\"RESIDENT_TYPE\"] == \"Resident\")]\n",
    "        sns.lineplot(data=county_proc_data, x=\"YEAR\", y=\"PROC_COUNT\", hue=\"PROCEDURE\", ax=axes[2], palette=treatment_colors, marker=\"o\")\n",
    "        axes[2].set_title(f\"Procedure Counts for {county}\")\n",
    "        axes[2].set_xlabel(\"Year\")\n",
    "        axes[2].set_ylabel(\"Procedure Count\")\n",
    "\n",
    "        plt.suptitle(f\"Counts for {county}\", y=1.05)\n",
    "        plt.tight_layout(pad=3.0)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the original dataframes.\n",
    "chd_inp_proc_agg_by_pt = chd_inp_df.groupby([\"YEAR\", \"PTCOUNTY_NAME\", \"PROCEDURE\", \"RESIDENT_TYPE\"]).size().reset_index(name=\"PROC_COUNT\")\n",
    "chd_ed_diag_agg_by_pt = chd_ed_df.groupby([\"YEAR\", \"PTCOUNTY_NAME\", \"RESIDENT_TYPE\"]).size().reset_index(name=\"DIAG_COUNT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two new columns POPULATION, PROC_FRAC_BY_COUNTY = PROC_COUNT/POPULATION and DIAG_FRAC_BY_COUNTY = DIAG_COUNT/POPULATION\n",
    "for county in pop_by_county_dics.keys():\n",
    "    for year in range(2015, 2024):\n",
    "        # Create the correct mask for current county and year\n",
    "        county_proc_mask = (chd_inp_proc_agg_by_pt[\"PTCOUNTY_NAME\"] == county) & (chd_inp_proc_agg_by_pt[\"YEAR\"] == year)\n",
    "        county_diag_mask = (chd_ed_diag_agg_by_pt[\"PTCOUNTY_NAME\"] == county) & (chd_ed_diag_agg_by_pt[\"YEAR\"] == year)\n",
    "        # Get the population for the current county and year\n",
    "        population = pop_by_county_dics[county].get(str(year))\n",
    "        # Apply the calculation if population is not None\n",
    "        if population is not None:\n",
    "            chd_inp_proc_agg_by_pt.loc[county_proc_mask, \"POPULATION\"] = population\n",
    "            chd_inp_proc_agg_by_pt.loc[county_proc_mask, \"PROC_FRAC_BY_COUNTY\"] = (chd_inp_proc_agg_by_pt.loc[county_proc_mask, \"PROC_COUNT\"] / population)\n",
    "            chd_ed_diag_agg_by_pt.loc[county_diag_mask, \"POPULATION\"] = population\n",
    "            chd_ed_diag_agg_by_pt.loc[county_diag_mask, \"DIAG_FRAC_BY_COUNTY\"] = (chd_ed_diag_agg_by_pt.loc[county_diag_mask, \"DIAG_COUNT\"] / population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique counties\n",
    "unique_counties = chd_inp_proc_agg_by_pt[\"PTCOUNTY_NAME\"].unique()\n",
    "\n",
    "# plot the distribution of the PROC_FRAC_BY_COUNTY\n",
    "num_plots_per_row = 3\n",
    "total_plots = len(unique_counties) * len(treatments[:-1])\n",
    "num_rows = total_plots // num_plots_per_row + (total_plots % num_plots_per_row > 0)\n",
    "fig, axes = plt.subplots(num_rows, num_plots_per_row, figsize=(20, num_rows * 5))\n",
    "axes = axes.flatten()  \n",
    "\n",
    "plot_index = 0 \n",
    "for county in unique_counties:\n",
    "    for procedure in treatments[:-1]:\n",
    "        county_proc_data =  chd_inp_proc_agg_by_pt[(chd_inp_proc_agg_by_pt[\"PTCOUNTY_NAME\"] == county) & \n",
    "                                                   (chd_inp_proc_agg_by_pt[\"RESIDENT_TYPE\"] == \"Resident\") & \n",
    "                                                   (chd_inp_proc_agg_by_pt[\"PROCEDURE\"] == procedure)]\n",
    "        sns.histplot(county_proc_data[\"PROC_FRAC_BY_COUNTY\"].dropna(), ax=axes[plot_index], kde=True)\n",
    "        axes[plot_index].set_title(f\"{procedure} in {county}\")\n",
    "        axes[plot_index].set_xlabel(\"PROC_FRAC_BY_COUNTY\")\n",
    "        axes[plot_index].set_ylabel(\"Frequency\")\n",
    "        \n",
    "        plot_index += 1 \n",
    "for j in range(plot_index, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique counties\n",
    "unique_counties = chd_inp_proc_agg_by_pt[\"PTCOUNTY_NAME\"].unique()\n",
    "\n",
    "# plot a scatter plot with regression line for PROC_FRAC_BY_COUNTY againts YEAR\n",
    "num_plots_per_row = 4\n",
    "total_plots = len(unique_counties) * len(treatments[:-1])\n",
    "num_rows = total_plots // num_plots_per_row + (total_plots % num_plots_per_row > 0)\n",
    "fig, axes = plt.subplots(num_rows, num_plots_per_row, figsize=(20, num_rows * 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "plot_index = 0 \n",
    "for county in unique_counties:\n",
    "    for procedure in treatments[:-1]:\n",
    "        county_proc_data = chd_inp_proc_agg_by_pt[(chd_inp_proc_agg_by_pt[\"PTCOUNTY_NAME\"] == county) & \n",
    "                                                   (chd_inp_proc_agg_by_pt[\"RESIDENT_TYPE\"] == \"Resident\") & \n",
    "                                                   (chd_inp_proc_agg_by_pt[\"PROCEDURE\"] == procedure)]\n",
    "        \n",
    "        sns.regplot(data=county_proc_data, x=\"YEAR\", y=\"PROC_FRAC_BY_COUNTY\", logx=True, ax=axes[plot_index])\n",
    "        axes[plot_index].set_title(f\"{procedure} in {county}\")\n",
    "        axes[plot_index].set_xlabel(\"YEAR\")\n",
    "        axes[plot_index].set_ylabel(\"PROC_FRAC_BY_COUNTY\")\n",
    "        \n",
    "        plot_index += 1 \n",
    "for j in range(plot_index, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the count of CABG + PCI into both CABG & and PCI and remove CABG + PCI. This is due to the sparse data points for CABG + PCI since its a rare case.\n",
    "for county in chd_inp_proc_agg_by_pt['PTCOUNTY_NAME'].unique():\n",
    "    for year in chd_inp_proc_agg_by_pt['YEAR'].unique():\n",
    "        chd_inp_proc_agg_by_pt[\"PROC_FRAC_BY_COUNTY\"] =  chd_inp_proc_agg_by_pt[\"PROC_FRAC_BY_COUNTY\"].fillna(0)\n",
    "        chd_inp_proc_agg_by_pt.loc[(chd_inp_proc_agg_by_pt[\"PROCEDURE\"] == \"CABG\")\n",
    "                                    & (chd_inp_proc_agg_by_pt[\"PTCOUNTY_NAME\"] == county)\n",
    "                                    & (chd_inp_proc_agg_by_pt[\"YEAR\"] == year), \"PROC_FRAC_BY_COUNTY\"] = sum(chd_inp_proc_agg_by_pt.loc[(chd_inp_proc_agg_by_pt[\"PROCEDURE\"] == \"CABG + PCI\")\n",
    "                                                                                                                                                    & (chd_inp_proc_agg_by_pt[\"PTCOUNTY_NAME\"] == county)\n",
    "                                                                                                                                                    & (chd_inp_proc_agg_by_pt[\"YEAR\"] == year), \"PROC_FRAC_BY_COUNTY\"],\n",
    "                                                                                                                        chd_inp_proc_agg_by_pt.loc[(chd_inp_proc_agg_by_pt[\"PROCEDURE\"] == \"CABG\")\n",
    "                                                                                                                                                    & (chd_inp_proc_agg_by_pt[\"PTCOUNTY_NAME\"] == county)\n",
    "                                                                                                                                                    & (chd_inp_proc_agg_by_pt[\"YEAR\"] == year), \"PROC_FRAC_BY_COUNTY\"])\n",
    "        chd_inp_proc_agg_by_pt.loc[(chd_inp_proc_agg_by_pt[\"PROCEDURE\"] == \"PCI\")\n",
    "                                    & (chd_inp_proc_agg_by_pt[\"PTCOUNTY_NAME\"] == county)\n",
    "                                    & (chd_inp_proc_agg_by_pt[\"YEAR\"] == year), \"PROC_FRAC_BY_COUNTY\"] = sum(chd_inp_proc_agg_by_pt.loc[(chd_inp_proc_agg_by_pt[\"PROCEDURE\"] == \"CABG + PCI\")\n",
    "                                                                                                                                                    & (chd_inp_proc_agg_by_pt[\"PTCOUNTY_NAME\"] == county)\n",
    "                                                                                                                                                    & (chd_inp_proc_agg_by_pt[\"YEAR\"] == year), \"PROC_FRAC_BY_COUNTY\"],\n",
    "                                                                                                                        chd_inp_proc_agg_by_pt.loc[(chd_inp_proc_agg_by_pt[\"PROCEDURE\"] == \"PCI\")\n",
    "                                                                                                                                                    & (chd_inp_proc_agg_by_pt[\"PTCOUNTY_NAME\"] == county)\n",
    "                                                                                                                                                    & (chd_inp_proc_agg_by_pt[\"YEAR\"] == year), \"PROC_FRAC_BY_COUNTY\"])\n",
    "chd_inp_proc_agg_by_pt = chd_inp_proc_agg_by_pt[~((chd_inp_proc_agg_by_pt[\"PROCEDURE\"] == \"CABG + PCI\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Using a GLM we are going to find the best fit line for the time series data. The coefficients will be used in a clustering algorithm to cluster the counties that have similar trends for diagnostics and treatments procedures seperately <b/> \n",
    "1. First normalize the countys by dividng the count by the population(i.e. PROC_FRAC_BY_COUNTY and DIAG_FRAC_BY_COUNTY)\n",
    "2. Year would be the independent variables. Encode as a continous value between 0.1 and 0.99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a GLM for procedure fraction and diagnostic fractions to estimate the trend.\n",
    "num_plots_per_row = 3\n",
    "total_plots = len(unique_counties) * (len(treatments[:-1]) + 1)\n",
    "num_rows = total_plots // num_plots_per_row + (total_plots % num_plots_per_row > 0)\n",
    "fig, axes = plt.subplots(num_rows, num_plots_per_row, figsize=(20, num_rows * 5))\n",
    "axes = axes.flatten()  \n",
    "\n",
    "year_to_x = {year: x for year, x in zip(chd_inp_proc_agg_by_pt[\"YEAR\"].unique(), np.linspace(0.1, 0.99, len(chd_inp_proc_agg_by_pt[\"YEAR\"].unique())))}\n",
    "diag_coeff_vector = {}\n",
    "proc_coeff_vector = {}\n",
    "\n",
    "plot_index = 0\n",
    "for county in unique_counties:\n",
    "    proc_coeff_vector[county] = []\n",
    "    diag_coeff_vector[county] = []\n",
    "    for procedure in treatments[:-1]:\n",
    "        # Filter data for the current county and procedure\n",
    "        county_proc_data = chd_inp_proc_agg_by_pt[(chd_inp_proc_agg_by_pt['PTCOUNTY_NAME'] == county) &\n",
    "                                                   (chd_inp_proc_agg_by_pt[\"RESIDENT_TYPE\"] == \"Resident\") & \n",
    "                                                   (chd_inp_proc_agg_by_pt['PROCEDURE'] == procedure)]\n",
    "        \n",
    "        # Drop rows with NaN values in either 'PROC_FAC_BY_COUNTY' or 'POPULATION'\n",
    "        county_proc_data = county_proc_data.dropna(subset=['PTCOUNTY_NAME', 'PROC_FRAC_BY_COUNTY'])\n",
    "        if not county_proc_data.empty:\n",
    "            # fit glm to treatment procedures\n",
    "            county_proc_data['X'] = county_proc_data['YEAR'].map(year_to_x)\n",
    "            model = smf.glm(formula=\"PROC_FRAC_BY_COUNTY ~ X \", data=county_proc_data, \n",
    "                            family=sm.families.Binomial()).fit()\n",
    "            proc_coeff_vector[county].append(model.params[\"Intercept\"])\n",
    "            proc_coeff_vector[county].append(model.params[\"X\"])\n",
    "\n",
    "            # plot the fitted GLM line in the scatter plot.\n",
    "            x_pred = np.linspace(county_proc_data[\"X\"].min(), county_proc_data[\"X\"].max(), 100)\n",
    "            y_pred = model.predict(pd.DataFrame({\"X\": x_pred}))\n",
    "            axes[plot_index].scatter(county_proc_data[\"X\"], county_proc_data[\"PROC_FRAC_BY_COUNTY\"], label=\"Actual\", alpha=0.6)\n",
    "            axes[plot_index].plot(x_pred, y_pred, color='red', label='Fitted GLM')\n",
    "            axes[plot_index].set_title(f\"{procedure} in {county}\")\n",
    "            axes[plot_index].set_xlabel(\"Year\")\n",
    "            axes[plot_index].set_ylabel(\"PROC_FRAC_BY_COUNTY\")\n",
    "            axes[plot_index].legend()\n",
    "\n",
    "            plot_index += 1\n",
    "\n",
    "    county_diag_data = chd_ed_diag_agg_by_pt[(chd_ed_diag_agg_by_pt['PTCOUNTY_NAME'] == county) &\n",
    "                                                   (chd_ed_diag_agg_by_pt[\"RESIDENT_TYPE\"] == \"Resident\")]\n",
    "    # fit glm to diagnostics\n",
    "    if not county_diag_data.empty:\n",
    "        county_diag_data['X'] = county_diag_data['YEAR'].map(year_to_x)\n",
    "        model = smf.glm(formula=\"DIAG_FRAC_BY_COUNTY ~ X \", data=county_diag_data, \n",
    "                        family=sm.families.Binomial()).fit()\n",
    "        diag_coeff_vector[county].append(model.params[\"Intercept\"])\n",
    "        diag_coeff_vector[county].append(model.params[\"X\"])\n",
    "\n",
    "        # plot the fitted GLM line in the scatter plot.\n",
    "        x_pred = np.linspace(county_diag_data[\"X\"].min(), county_diag_data[\"X\"].max(), 100)\n",
    "        y_pred = model.predict(pd.DataFrame({\"X\": x_pred}))\n",
    "        axes[plot_index].scatter(county_diag_data[\"X\"], county_diag_data[\"DIAG_FRAC_BY_COUNTY\"], label=\"Actual\", alpha=0.6)\n",
    "        axes[plot_index].plot(x_pred, y_pred, color='red', label='Fitted GLM')\n",
    "        axes[plot_index].set_title(f\"diagnosis in {county}\")\n",
    "        axes[plot_index].set_xlabel(\"Year\")\n",
    "        axes[plot_index].set_ylabel(\"DIAG_FRAC_BY_COUNTY\")\n",
    "        axes[plot_index].legend()\n",
    "\n",
    "        plot_index += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the maximum length of coefficient lists\n",
    "max_length = max(len(coeffs) for coeffs in proc_coeff_vector.values() if coeffs)\n",
    "\n",
    "# pad coefficient lists with zeros to ensure uniform length\n",
    "padded_proc_coeffs = {county: coeffs + [0] * (max_length - len(coeffs)) for county, coeffs in proc_coeff_vector.items()}\n",
    "\n",
    "# convert the dictionary to a DataFrame\n",
    "proc_coeff_df = pd.DataFrame.from_dict(padded_proc_coeffs, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the maximum length of coefficient lists\n",
    "max_length = max(len(coeffs) for coeffs in diag_coeff_vector.values() if coeffs)\n",
    "\n",
    "# pad coefficient lists with zeros to ensure uniform length\n",
    "padded_diag_coeffs = {county: coeffs + [0] * (max_length - len(coeffs)) for county, coeffs in diag_coeff_vector.items()}\n",
    "\n",
    "# convert the dictionary to a DataFrame\n",
    "diag_coeff_df = pd.DataFrame.from_dict(padded_diag_coeffs, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster the treatment procedure GLM coefficients using K-Means.\n",
    "inertias = []\n",
    "K = range(1, 10) \n",
    "for k in K:\n",
    "    kmeans_model = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans_model.fit(proc_coeff_df)\n",
    "    inertias.append(kmeans_model.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(K, inertias, \"bx-\")\n",
    "plt.xlabel(\"Number of county clusters in procedures\")\n",
    "plt.ylabel(\"Sum of squared distances (Inertia)\")\n",
    "plt.title(\"The Elbow Method showing the optimal k\")\n",
    "plt.xticks(K)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster the treatment procedure GLM coefficients using K-Means\n",
    "inertias = []\n",
    "K = range(1, 10) \n",
    "for k in K:\n",
    "    kmeans_model = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans_model.fit(diag_coeff_df)\n",
    "    inertias.append(kmeans_model.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(K, inertias, \"bx-\")\n",
    "plt.xlabel(\"Number of county clusters in diagnosis\")\n",
    "plt.ylabel(\"Sum of squared distances (Inertia)\")\n",
    "plt.title(\"The Elbow Method showing the optimal k\")\n",
    "plt.xticks(K)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(proc_coeff_df)\n",
    "proc_coeff_df[\"cluster\"] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(diag_coeff_df)\n",
    "diag_coeff_df[\"cluster\"] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5)) \n",
    "\n",
    "# let's say we use the first two coefficients (columns 0 and 1) for the x and y axes\n",
    "sns.scatterplot(data=proc_coeff_df, x=0, y=1, hue='cluster', palette='viridis', ax=axes[0])\n",
    "sns.scatterplot(data=proc_coeff_df, x=2, y=3, hue='cluster', palette='viridis', ax=axes[1])\n",
    "\n",
    "plt.legend(title='Cluster')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's say we use the first two coefficients (columns 0 and 1) for the x and y axes\n",
    "sns.scatterplot(data=diag_coeff_df, x=0, y=1, hue='cluster', palette='viridis')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proc_coeff_df[proc_coeff_df[\"cluster\"] == 0].index)\n",
    "print(diag_coeff_df[diag_coeff_df[\"cluster\"] == 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proc_coeff_df[proc_coeff_df[\"cluster\"] == 1].index)\n",
    "print(diag_coeff_df[diag_coeff_df[\"cluster\"] == 1].index)\n",
    "print(diag_coeff_df[diag_coeff_df[\"cluster\"] == 2].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Hierachical clustering was used as the best clustering technique for this use case. K-Means clustering does provid a way see how coefficients of PCI and CABG cluster the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster the diagnostic GLM coefficients using Agglomerative Hierarchical clustering.\n",
    "clustering = AgglomerativeClustering(n_clusters=5, linkage=\"ward\")\n",
    "clustering.fit(diag_coeff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dendogram\n",
    "diag_linkage_matrix = ward(diag_coeff_df)\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(diag_linkage_matrix, labels=diag_coeff_df.index.tolist(), leaf_rotation=90, leaf_font_size=10)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = fcluster(diag_linkage_matrix, 5, criterion=\"distance\")\n",
    "diag_coeff_df[\"cluster\"] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster the treatment procedures GLM coefficients using Agglomerative Hierarchical clustering.\n",
    "clustering = AgglomerativeClustering(n_clusters=5, linkage=\"ward\")\n",
    "clustering.fit(proc_coeff_df.loc[:,2:3])\n",
    "proc_linkage_matrix = ward(proc_coeff_df.loc[:,2:3])\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(proc_linkage_matrix, labels=proc_coeff_df.index.tolist(), leaf_rotation=90, leaf_font_size=10)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = fcluster(proc_linkage_matrix, 5, criterion=\"distance\")\n",
    "proc_coeff_df[\"cluster\"] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chd_inp_df[\"CLUSTER\"] = np.nan\n",
    "chd_inp_proc_agg_by_pt[\"CLUSTER\"] = np.nan\n",
    "\n",
    "for x, row in proc_coeff_df.iterrows():\n",
    "    chd_inp_df.loc[chd_inp_df[\"PTCOUNTY_NAME\"] == x, \"CLUSTER\"] = str(row[\"cluster\"])\n",
    "    chd_inp_proc_agg_by_pt.loc[chd_inp_proc_agg_by_pt[\"PTCOUNTY_NAME\"] == x,  \"CLUSTER\"] = int(row[\"cluster\"])\n",
    "\n",
    "chd_ed_df[\"CLUSTER\"] = np.nan\n",
    "chd_ed_diag_agg_by_pt[\"CLUSTER\"] = np.nan\n",
    "\n",
    "for x, row in diag_coeff_df.iterrows():\n",
    "    chd_ed_df.loc[chd_ed_df[\"PTCOUNTY_NAME\"] == x, \"CLUSTER\"] = str(row[\"cluster\"])\n",
    "    chd_ed_diag_agg_by_pt.loc[chd_ed_diag_agg_by_pt[\"PTCOUNTY_NAME\"] == x,  \"CLUSTER\"] = int(row[\"cluster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_by_county_melt[\"Year\"] = pop_by_county_melt[\"Year\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot time series plots for the clustered counties to see how they differ\n",
    "chd_inp_proc_clus_pt = chd_inp_df.groupby([\"YEAR\", \"PTCOUNTY_NAME\", \"PROCEDURE\", \"RESIDENT_TYPE\", \"CLUSTER\"]).size().reset_index(name=\"PROC_COUNT\")\n",
    "chd_ed_diag_clus_pt = chd_ed_df.groupby([\"YEAR\", \"PTCOUNTY_NAME\", \"RESIDENT_TYPE\", \"CLUSTER\"]).size().reset_index(name=\"DIAG_COUNT\")\n",
    "\n",
    "df_inp = chd_inp_proc_clus_pt.rename(columns={\"PTCOUNTY_NAME\": \"County\", \"YEAR\": \"Year\"})\n",
    "df_ed = chd_ed_diag_clus_pt.rename(columns={\"PTCOUNTY_NAME\": \"County\", \"YEAR\": \"Year\"})\n",
    "\n",
    "merged_inp_df = pd.merge(df_inp, pop_by_county_melt, how=\"left\", on=[\"Year\", \"County\"])\n",
    "merged_inp_df['FRAC_PROC_BY_COUNTY'] = merged_inp_df['PROC_COUNT'] / merged_inp_df['Population']\n",
    "merged_ed_df = pd.merge(df_ed, pop_by_county_melt, how=\"left\", on=[\"Year\", \"County\"])\n",
    "merged_ed_df['FRAC_DIAG_BY_COUNTY'] = merged_ed_df['DIAG_COUNT'] / merged_ed_df['Population']\n",
    "\n",
    "for cluster in (\"1.0\", \"2.0\", \"3.0\"):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(20, 15)) \n",
    "\n",
    "    county_diag_data = merged_ed_df[(merged_ed_df[\"CLUSTER\"] == cluster)]\n",
    "    sns.lineplot(data=county_diag_data, x=\"Year\", y=\"FRAC_DIAG_BY_COUNTY\", ax=axes[0], marker=\"o\")\n",
    "    axes[0].set_title(f\"Diagnosis Counts for patient county {cluster}\")\n",
    "    axes[0].set_xlabel(\"Year\")\n",
    "    axes[0].set_ylabel(\"Diagnosis Count\")\n",
    "\n",
    "    county_proc_data = merged_inp_df[(merged_inp_df[\"CLUSTER\"] == cluster)]\n",
    "    sns.lineplot(data=county_proc_data, x=\"Year\", y=\"FRAC_PROC_BY_COUNTY\", hue=\"PROCEDURE\", ax=axes[1], palette=treatment_colors, marker=\"o\")\n",
    "    axes[1].set_title(f\"Procedure Counts for patient county {cluster}\")\n",
    "    axes[1].set_xlabel(\"Year\")\n",
    "    axes[1].set_ylabel(\"Procedure Count\")\n",
    "    \n",
    "    plt.tight_layout(pad=3.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the original datasets by year quater this time.\n",
    "chd_inp_proc_pt_by_age = chd_inp_df.groupby([\"YEAR\", \"YEAR_QTR\", \"AGE_GROUP\",\"PTCOUNTY_NAME\", \"PROCEDURE\", \"RESIDENT_TYPE\"]).size().reset_index(name=\"PROC_COUNT\")\n",
    "chd_ed_diag_pt_by_age = chd_ed_df.groupby([\"YEAR\", \"YEAR_QTR\", \"AGE_GROUP\", \"PTCOUNTY_NAME\", \"RESIDENT_TYPE\"]).size().reset_index(name=\"DIAG_COUNT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the countis of PCI + CABG into PCI and CABG and remove PCI + CABG\n",
    "for county in chd_inp_proc_pt_by_age[\"PTCOUNTY_NAME\"].unique():\n",
    "    for year in chd_inp_proc_pt_by_age[\"YEAR_QTR\"].unique():\n",
    "        for age_group in chd_inp_proc_pt_by_age[\"AGE_GROUP\"].unique():\n",
    "            chd_inp_proc_pt_by_age[\"PROC_COUNT\"] =  chd_inp_proc_pt_by_age[\"PROC_COUNT\"].fillna(0)\n",
    "            chd_inp_proc_pt_by_age.loc[(chd_inp_proc_pt_by_age[\"PROCEDURE\"] == \"CABG\")\n",
    "                                        & (chd_inp_proc_pt_by_age[\"PTCOUNTY_NAME\"] == county)\n",
    "                                        & (chd_inp_proc_pt_by_age[\"YEAR_QTR\"] == year)\n",
    "                                        & (chd_inp_proc_pt_by_age[\"AGE_GROUP\"] == age_group), \"PROC_COUNT\"] = sum(chd_inp_proc_pt_by_age.loc[(chd_inp_proc_pt_by_age[\"PROCEDURE\"] == \"CABG + PCI\")\n",
    "                                                                                                                                                        & (chd_inp_proc_pt_by_age[\"PTCOUNTY_NAME\"] == county)\n",
    "                                                                                                                                                        & (chd_inp_proc_pt_by_age[\"YEAR_QTR\"] == year)\n",
    "                                                                                                                                                        & (chd_inp_proc_pt_by_age[\"AGE_GROUP\"] == age_group), \"PROC_COUNT\"],\n",
    "                                                                                                                            chd_inp_proc_pt_by_age.loc[(chd_inp_proc_pt_by_age[\"PROCEDURE\"] == \"CABG\")\n",
    "                                                                                                                                                        & (chd_inp_proc_pt_by_age[\"PTCOUNTY_NAME\"] == county)\n",
    "                                                                                                                                                        & (chd_inp_proc_pt_by_age[\"YEAR_QTR\"] == year)\n",
    "                                                                                                                                                        & (chd_inp_proc_pt_by_age[\"AGE_GROUP\"] == age_group), \"PROC_COUNT\"])\n",
    "            chd_inp_proc_pt_by_age.loc[(chd_inp_proc_pt_by_age[\"PROCEDURE\"] == \"PCI\")\n",
    "                                        & (chd_inp_proc_pt_by_age[\"PTCOUNTY_NAME\"] == county)\n",
    "                                        & (chd_inp_proc_pt_by_age[\"YEAR_QTR\"] == year)\n",
    "                                        & (chd_inp_proc_pt_by_age[\"AGE_GROUP\"] == age_group), \"PROC_COUNT\"] = sum(chd_inp_proc_pt_by_age.loc[(chd_inp_proc_pt_by_age[\"PROCEDURE\"] == \"CABG + PCI\")\n",
    "                                                                                                                                                        & (chd_inp_proc_pt_by_age[\"PTCOUNTY_NAME\"] == county)\n",
    "                                                                                                                                                        & (chd_inp_proc_pt_by_age[\"YEAR_QTR\"] == year)\n",
    "                                                                                                                                                        & (chd_inp_proc_pt_by_age[\"AGE_GROUP\"] == age_group), \"PROC_COUNT\"],\n",
    "                                                                                                                            chd_inp_proc_pt_by_age.loc[(chd_inp_proc_pt_by_age[\"PROCEDURE\"] == \"PCI\")\n",
    "                                                                                                                                                        & (chd_inp_proc_pt_by_age[\"PTCOUNTY_NAME\"] == county)\n",
    "                                                                                                                                                        & (chd_inp_proc_pt_by_age[\"YEAR_QTR\"] == year)\n",
    "                                                                                                                                                        & (chd_inp_proc_pt_by_age[\"AGE_GROUP\"] == age_group), \"PROC_COUNT\"])\n",
    "chd_inp_proc_pt_by_age = chd_inp_proc_pt_by_age[~((chd_inp_proc_pt_by_age[\"PROCEDURE\"] == \"CABG + PCI\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_population_by_age_group(file_name):\n",
    "  \"\"\"\n",
    "  Group the population by age group and create seperate dataframes.\n",
    "  \"\"\"\n",
    "  pop_list = {}\n",
    "  # open the excel file\n",
    "  with pd.ExcelFile(file_name) as xls:\n",
    "    # read through age group sheets\n",
    "    for i in range(35, 85, 10):\n",
    "      df_males = pd.read_excel(xls, sheet_name=f'{i}to{i+9}-Males')\n",
    "      df_females = pd.read_excel(xls, sheet_name=f'{i}to{i+9}-Females')\n",
    "      # aggregate males and females by age groups\n",
    "      pop_list[f'{i}-{i+9}'] = aggregate_gender(df_males, df_females)\n",
    "\n",
    "    df_males = pd.read_excel(xls, sheet_name=f'85+-Males')\n",
    "    df_females = pd.read_excel(xls, sheet_name=f'85+-Females')\n",
    "    # aggregate males and females by age groups\n",
    "    pop_list['>=85'] = aggregate_gender(df_males, df_females)\n",
    "  return pop_list\n",
    "\n",
    "def aggregate_gender(df_males, df_females):\n",
    "  \"\"\"\n",
    "  Aggregate males and females population count.\n",
    "  \"\"\"\n",
    "  # combine the two data frames\n",
    "  df_total = pd.merge(df_males, df_females, on=\"County\", suffixes=(\"_male\", \"_female\"))\n",
    "  for year in range(1970, 2024):  # adjust range according to your data\n",
    "    year_ = str(year)\n",
    "    if year_+'_male' in df_total and year_+'_female' in df_total:\n",
    "        df_total[year] = df_total[year_+'_male'] + df_total[year_+'_female']\n",
    "        df_total.drop(columns=[year_+'_male', year_+'_female'], inplace=True)\n",
    "  return df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare population dataframe\n",
    "pop_list_by_age_county = get_population_by_age_group(\"data/PopByCountyGroupsConfigured.xlsx\")\n",
    "\n",
    "melted_pop_dfs = []\n",
    "for age_group, df in pop_list_by_age_county.items():\n",
    "    melted_df = df.melt(id_vars=\"County\", var_name=\"Year\", value_name=age_group)\n",
    "    melted_pop_dfs.append(melted_df)\n",
    "pop_df = melted_pop_dfs[0]\n",
    "for df in melted_pop_dfs[1:]:\n",
    "    pop_df = pd.merge(pop_df, df, on=[\"County\", \"Year\"], how=\"inner\")\n",
    "numeric_columns = pop_df.select_dtypes(include=['float']).columns\n",
    "pop_df[numeric_columns] = pop_df[numeric_columns].apply(lambda x: x.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the PROC_FRAC_BY_COUNTY and DIAG_FRAC_BY_COUNTY\n",
    "for county in pop_df[\"County\"].unique():\n",
    "    for year in range(2015, 2024):\n",
    "        for age_group in chd_inp_proc_pt_by_age[\"AGE_GROUP\"].unique():\n",
    "            # create the mask for current county and year\n",
    "            county_proc_mask = (chd_inp_proc_pt_by_age[\"PTCOUNTY_NAME\"] == county) & (chd_inp_proc_pt_by_age[\"YEAR\"] == year) & (chd_inp_proc_pt_by_age[\"AGE_GROUP\"] == age_group)\n",
    "            county_diag_mask = (chd_ed_diag_pt_by_age[\"PTCOUNTY_NAME\"] == county) & (chd_ed_diag_pt_by_age[\"YEAR\"] == year) & (chd_ed_diag_pt_by_age[\"AGE_GROUP\"] == age_group)\n",
    "            # get the population for the current county and year\n",
    "            population = pop_df[(pop_df[\"County\"] == county) & (pop_df[\"Year\"] == year)][str(age_group)].iloc[0]\n",
    "            # apply the calculation if population is not None\n",
    "            if population is not None:\n",
    "                chd_inp_proc_pt_by_age.loc[county_proc_mask, \"POPULATION\"] = population\n",
    "                chd_inp_proc_pt_by_age.loc[county_proc_mask, \"PROC_FRAC_BY_COUNTY\"] = (chd_inp_proc_pt_by_age.loc[county_proc_mask, \"PROC_COUNT\"] / population)\n",
    "                chd_ed_diag_pt_by_age.loc[county_diag_mask, \"POPULATION\"] = population\n",
    "                chd_ed_diag_pt_by_age.loc[county_diag_mask, \"DIAG_FRAC_BY_COUNTY\"] = (chd_ed_diag_pt_by_age.loc[county_diag_mask, \"DIAG_COUNT\"] / population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the inpatient data without age group\n",
    "chd_inp_pt_by_age_agg = chd_inp_proc_pt_by_age.groupby(['YEAR_QTR', 'PTCOUNTY_NAME', 'RESIDENT_TYPE', \"PROCEDURE\"]).agg(\n",
    "                                                            PROC_COUNT=pd.NamedAgg(column='PROC_COUNT', aggfunc='sum')\n",
    "                                                        ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the inpatient data without age group\n",
    "chd_ed_diag_pt_by_age_agg = chd_ed_diag_pt_by_age.groupby(['YEAR', 'PTCOUNTY_NAME', 'RESIDENT_TYPE']).agg(\n",
    "                                                            DIAG_COUNT=pd.NamedAgg(column='DIAG_COUNT', aggfunc='sum'),\n",
    "                                                            DIAG_FRAC_BY_COUNTY=pd.NamedAgg(column='DIAG_FRAC_BY_COUNTY', aggfunc='sum')\n",
    "                                                        ).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series modeling CHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_arima_model(X):\n",
    "\t\"\"\"\"\n",
    "\tEvaluate the arima model with the test dataset. train test split is 70/30\n",
    "\t\"\"\"\n",
    "\t# prepare training dataset\n",
    "\ttrain_size = int(len(X) * 0.7)\n",
    "\ttrain, test = X[0:train_size], X[train_size:]\n",
    "\t# make predictions\n",
    "\tmodel  = auto_arima(train, error_action=\"ignore\", trace=False, suppress_warnings=True, maxiter=5, seasonal=True, stepwise=True)\n",
    "\tpredictions = model.predict(n_periods=len(test))\t\n",
    "\t# calculate out of sample error\n",
    "\terror_mape = mean_absolute_percentage_error(test, predictions.astype(int))\n",
    "\terror_mae = mean_absolute_error(test, predictions.astype(int))\n",
    "\terror_nmae = normalized_mean_absolute_error(test, predictions.astype(int))\n",
    "\treturn model, error_mae, error_nmae, error_mape\n",
    "\n",
    "def evaluate_exponential_smoothing_model(X):\n",
    "\t\"\"\"\n",
    "\tEvaluate the Holt Winter's exponential smoothing algorithm on the test dataset. train test split is 70/30\n",
    "\t\"\"\"\n",
    "\t# prepare training dataset\n",
    "\ttrain_size = int(len(X) * 0.7)\n",
    "\ttrain, test = X[0:train_size], X[train_size:]\n",
    "\t# make predictions\n",
    "\tmodel  = ExponentialSmoothing(np.array(train[\"DIAG_COUNT\"]), seasonal_periods=2, trend=\"add\", seasonal=\"add\").fit()\n",
    "\tpredictions = model.forecast(len(test))\t\n",
    "\t# calculate out of sample error\n",
    "\terror_mape = mean_absolute_percentage_error(test[\"DIAG_COUNT\"].to_list(), predictions.astype(int))\n",
    "\terror_mae = mean_absolute_error(test[\"DIAG_COUNT\"].to_list(), predictions.astype(int))\n",
    "\terror_nmae = normalized_mean_absolute_error(test[\"DIAG_COUNT\"].to_list(), predictions.astype(int))\n",
    "\treturn model, error_mae, error_nmae, error_mape\n",
    "\n",
    "def make_series_stationary(df, column, max_diff=1):\n",
    "\tstationary_df = pd.DataFrame()\n",
    "\tstationary_df[\"YEAR_QTR\"] = df[\"YEAR_QTR\"]\n",
    "\tseries = df[column]\n",
    "\tfor i in range(max_diff):\n",
    "\t\tresult = adfuller(series.dropna(), autolag=\"AIC\")  # Ensure to drop NA values\n",
    "\t\tif result[1] > 0.05:\n",
    "\t\t\t# the series is not stationary, apply differencing\n",
    "\t\t\tstationary_series = series.diff().dropna()\n",
    "\t\telse:\n",
    "\t\t\tstationary_series = series\n",
    "\t\tstationary_df[column] = stationary_series\n",
    "\treturn stationary_df[column].fillna(method=\"bfill\"), result[1]\n",
    "\n",
    "def normalized_mean_absolute_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred)) / (np.max(y_true) - np.min(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_exponential_smoothing_model(train, test, cfg):\n",
    "    try:\n",
    "        # fit the model\n",
    "        model = ExponentialSmoothing(\n",
    "            train,\n",
    "            seasonal_periods=cfg.get('seasonal_periods'),\n",
    "            trend=cfg.get('trend'),\n",
    "            seasonal=cfg.get('seasonal'),\n",
    "            damped_trend=cfg.get('damped_trend', False)\n",
    "        ).fit(optimized=True, remove_bias=cfg.get('remove_bias', False))\n",
    "        # forecast\n",
    "        predictions = model.forecast(len(test))\n",
    "        # compute error metrics\n",
    "        mae = mean_absolute_percentage_error(test, predictions)\n",
    "        return cfg, mae\n",
    "    except Exception as e:\n",
    "        print(f'Error in config: {cfg} - {e}')\n",
    "        return cfg, np.nan\n",
    "# Grid search across combinations of configurations\n",
    "def exp_smoothing_grid_search(series, cfg_list, n_test):\n",
    "    # split data into train and test\n",
    "    train, test = series[0:-n_test], series[-n_test:]\n",
    "\n",
    "    # evaluate configs\n",
    "    scores = [evaluate_exponential_smoothing_model(train, test, cfg) for cfg in cfg_list]\n",
    "    # remove configurations with errors\n",
    "    scores = [s for s in scores if not np.isnan(s[1])]\n",
    "\n",
    "    # sort configs by error, ascending\n",
    "    scores.sort(key=lambda s: s[1])\n",
    "\n",
    "    return scores\n",
    "\n",
    "# configuration for grid search\n",
    "cfg_list = [\n",
    "    {'seasonal_periods': p, 'trend': t, 'seasonal': s, 'damped_trend': d, 'use_boxcox': b, 'remove_bias': r}\n",
    "    for p, t, s, d, b, r in product(\n",
    "        [2, 4, 6],           # seasonal periods options\n",
    "        ['add', 'mul', None], # trend options\n",
    "        ['add', 'mul', None], # seasonal options\n",
    "        [True, False],        # damped trend options\n",
    "        [True, False],        # use boxcox options\n",
    "        [True, False]         # remove bias options\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chd_ed_diag_pt_by_age.to_csv(\"data\\chd_ed_diag_pt_by_age.csv\")\n",
    "chd_inp_proc_pt_by_age.to_csv(\"data\\chd_inp_proc_pt_by_age.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit arima models for the treatment procedures in each county\n",
    "counties = chd_inp_pt_by_age_agg[\"PTCOUNTY_NAME\"].unique()\n",
    "procedures = chd_inp_pt_by_age_agg[\"PROCEDURE\"].unique()\n",
    "\n",
    "results = []\n",
    "for county in counties:\n",
    "    for i, treatment in enumerate(procedures):\n",
    "        mask = (chd_inp_pt_by_age_agg[\"PTCOUNTY_NAME\"] == county) & (chd_inp_pt_by_age_agg[\"PROCEDURE\"] == treatment)\n",
    "        data = chd_inp_pt_by_age_agg.loc[mask]\n",
    "        if not data.empty:\n",
    "            m, mae, nmae, mape = evaluate_arima_model(data[\"PROC_COUNT\"])       \n",
    "            results.append({\n",
    "                \"County\": county,\n",
    "                \"Procedure\": treatment,\n",
    "                \"Model\": m,\n",
    "                \"MAE\": mae,\n",
    "                \"NMAE\": nmae,\n",
    "                \"MAPE\": mape\n",
    "            })     \n",
    "treatment_preds_results_df = pd.DataFrame(results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  NOTE: commented code - age wise model fitting was not yielding good results.\n",
    "\n",
    "# counties = chd_ed_diag_pt_by_age[\"PTCOUNTY_NAME\"].unique()\n",
    "# age_groups = chd_ed_diag_pt_by_age[\"AGE_GROUP\"].unique()\n",
    "# results = []\n",
    "# for county in counties:\n",
    "#     fig, axs = plt.subplots(2, 3, figsize=(20, 10))\n",
    "#     axs = axs.flatten()\n",
    "#     plt.suptitle(f\"Diagnosis count for county: {county}\", fontsize=16, y=1.02)  \n",
    "\n",
    "#     for i, age_group in enumerate(age_groups):\n",
    "#         ax = axs[i]\n",
    "#         mask = (chd_ed_diag_pt_by_age[\"PTCOUNTY_NAME\"] == county) & (chd_ed_diag_pt_by_age[\"AGE_GROUP\"] == age_group)\n",
    "#         data = chd_ed_diag_pt_by_age.loc[mask]\n",
    "#         if not data.empty:\n",
    "#             sns.lineplot(data=data, x=\"YEAR_QTR\", y=\"DIAG_COUNT\", ax=ax, label=\"Original\")\n",
    "#             sns.lineplot(data=data, x=\"YEAR_QTR\", y=\"DIAG_COUNT_\", ax=ax, label=\"Stationary\", color='orange')\n",
    "#             m, mae, nmae, mape = evaluate_arima_model(data[\"DIAG_COUNT\"])       \n",
    "#             results.append({\n",
    "#                 \"County\": county,\n",
    "#                 \"Age_Group\": age_group,\n",
    "#                 \"Model\": m,\n",
    "#                 \"MAE\": mae,\n",
    "#                 \"NMAE\": nmae,\n",
    "#                 \"MAPE\": mape\n",
    "#             })\n",
    "\n",
    "#             ax.set_title(f\"{age_group} - {p}\")\n",
    "#             ax.set_ylabel('Diagnosis Count')\n",
    "#             ax.set_xlabel('Year Quarter')\n",
    "#             ax.tick_params(axis='x', rotation=90)\n",
    "    \n",
    "#     for j in range(i+1, 6):\n",
    "#         fig.delaxes(axs[j])\n",
    "\n",
    "#     plt.tight_layout()  # adjust the layout\n",
    "#     plt.show()       \n",
    "# results_df = pd.DataFrame(results)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counties = chd_ed_diag_pt_by_age[\"PTCOUNTY_NAME\"].unique()\n",
    "# age_groups = chd_ed_diag_pt_by_age[\"AGE_GROUP\"].unique()\n",
    "# results = []\n",
    "# for county in counties:\n",
    "#     fig, axs = plt.subplots(2, 3, figsize=(20, 10))\n",
    "#     axs = axs.flatten()\n",
    "#     plt.suptitle(f\"Diagnosis count for county: {county}\", fontsize=16, y=1.02)  \n",
    "\n",
    "#     for i, age_group in enumerate(age_groups):\n",
    "#         ax = axs[i]\n",
    "#         mask = (chd_ed_diag_pt_by_age[\"PTCOUNTY_NAME\"] == county) & (chd_ed_diag_pt_by_age[\"AGE_GROUP\"] == age_group)\n",
    "#         data = chd_ed_diag_pt_by_age.loc[mask]\n",
    "#         if not data.empty:\n",
    "#             plot_acf(data[\"DIAG_COUNT\"], ax=ax, lags=len(data)-1)\n",
    "#             ax.set_title(f\"ACF for {age_group}\", fontsize=10)\n",
    "#             ax.set_xlabel(\"Lags\")\n",
    "#             ax.set_ylable(\"Autocorrelation\")\n",
    "#         else:\n",
    "#             ax.set_visible(False)\n",
    "    \n",
    "#     for j in range(i+1, 6):\n",
    "#         fig.delaxes(axs[j])\n",
    "\n",
    "#     plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust the layout\n",
    "#     plt.show()       \n",
    "# results_df = pd.DataFrame(results)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit arima models for the diagnostics procedures in each county\n",
    "results = []\n",
    "for county in chd_ed_diag_pt_by_age_agg[\"PTCOUNTY_NAME\"].unique():\n",
    "    mask =  (chd_ed_diag_pt_by_age_agg[\"PTCOUNTY_NAME\"] == county)\n",
    "    data = chd_ed_diag_pt_by_age_agg.loc[mask]\n",
    "    m, mae, nmae, mape = evaluate_arima_model(data[\"DIAG_COUNT\"])       \n",
    "    results.append({\n",
    "        \"County\": county,\n",
    "        \"Model\": m,\n",
    "        \"MAE\": mae,\n",
    "        \"NMAE\": nmae,\n",
    "        \"MAPE\": mape\n",
    "    })\n",
    "\n",
    "diagnostics_preds_results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_preds_results_df.to_excel(\"results-treatments-ARIMA.xlsx\")\n",
    "diagnostics_preds_results_df.to_excel(\"results-diagnostics-ARIMA.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit exponential smoothing algorithm on diagnostics\n",
    "counties = chd_ed_diag_pt_by_age[\"PTCOUNTY_NAME\"].unique()\n",
    "results = []\n",
    "for county in counties:\n",
    "    mask = (chd_ed_diag_pt_by_age[\"PTCOUNTY_NAME\"] == county)\n",
    "    data = chd_ed_diag_pt_by_age.loc[mask]\n",
    "    best_cfg, best_score = exp_smoothing_grid_search(data[\"DIAG_COUNT\"], cfg_list, 4)[0]\n",
    "    results.append({\n",
    "            \"County\": county,\n",
    "            \"cfg\": best_cfg,\n",
    "            \"MAPE\": best_score\n",
    "    })\n",
    "diagnostics_preds_results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit exponential smoothing algorithm on treatment procedures\n",
    "counties = chd_ed_diag_pt_by_age[\"PTCOUNTY_NAME\"].unique()\n",
    "procedures = chd_inp_pt_by_age_agg[\"PROCEDURE\"].unique()\n",
    "results = []\n",
    "for county in counties:\n",
    "    for i, procedure in enumerate(procedures):\n",
    "       mask = (chd_ed_diag_pt_by_age[\"PTCOUNTY_NAME\"] == county) & (chd_ed_diag_pt_by_age[\"PROCEDURE\"] == procedure)\n",
    "       data = chd_ed_diag_pt_by_age.loc[mask]\n",
    "       best_cfg, best_score = exp_smoothing_grid_search(data[\"PROC_COUNT\"], cfg_list, 4)[0]\n",
    "       results.append({\n",
    "              \"County\": county,\n",
    "              \"cfg\": best_cfg,\n",
    "              \"MAPE\": best_score\n",
    "        })\n",
    "treatment_preds_results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_preds_results_df.to_excel(\"results-treatments-EXPONENTIAL-SMOOTHING.xlsx\")\n",
    "diagnostics_preds_results_df.to_excel(\"results-diagnostics-EXPONENTIAL-SMOOTHING.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The results-treatments-ARIMA, results-diagnostics-EXPONENTIAL-SMOOTHING and results-treatments-EXPONENTIAL-SMOOTHING, results-diagnostics-ARIMA  were combined manually on excel to filter out the best model and the resulting files were named:\n",
    "1. diagnosis-model-configs.xlsx\n",
    "2. treatments-model-configs.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a time sries plot for the diagnosis counts by year quater.\n",
    "for county in chd_ed_diag_pt_by_age[\"PTCOUNTY_NAME\"].unique():\n",
    "    data = chd_ed_diag_pt_by_age[chd_ed_diag_pt_by_age[\"PTCOUNTY_NAME\"]==county]\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.lineplot(data=data, x=\"YEAR_QTR\", y=\"DIAG_COUNT\", markers='o')\n",
    "    plt.title(f\"Diagnosis count fo county: {county}\")\n",
    "    plt.ylabel(\"diagnosis count\")\n",
    "    plt.xlabel(\"year\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network analysis to observe the percentage of patients travelling to difference facility counties for treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only resident data and group by year again.\n",
    "chd_inp_tr_by_fc = chd_inp_df.groupby([\"YEAR\", \"PTCOUNTY_NAME\", \"FAC_COUNTY_NAME\", \"PROCEDURE\", \"RESIDENT_TYPE\"]).size().reset_index(name=\"PROC_COUNT\")\n",
    "chd_inp_tr_by_fc = chd_inp_tr_by_fc[~(chd_inp_tr_by_fc[\"RESIDENT_TYPE\"]==\"Non Resident\")]\n",
    "chd_ed_diag_by_fc = chd_inp_df.groupby([\"YEAR\", \"PTCOUNTY_NAME\", \"FAC_COUNTY_NAME\", \"RESIDENT_TYPE\"]).size().reset_index(name=\"DIAG_COUNT\")\n",
    "chd_ed_diag_by_fc = chd_ed_diag_by_fc[~(chd_ed_diag_by_fc[\"RESIDENT_TYPE\"]==\"Non Resident\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for county in chd_inp_tr_by_fc[\"PTCOUNTY_NAME\"].unique():\n",
    "    for year in chd_inp_tr_by_fc[\"YEAR\"].unique():\n",
    "        chd_inp_tr_by_fc[\"PROC_COUNT\"] =  chd_inp_tr_by_fc[\"PROC_COUNT\"].fillna(0)\n",
    "        chd_inp_tr_by_fc.loc[(chd_inp_tr_by_fc[\"PROCEDURE\"] == \"CABG\")\n",
    "                                    & (chd_inp_tr_by_fc[\"PTCOUNTY_NAME\"] == county)\n",
    "                                    & (chd_inp_tr_by_fc[\"YEAR\"] == year), \"PROC_COUNT\"] = sum(chd_inp_tr_by_fc.loc[(chd_inp_tr_by_fc[\"PROCEDURE\"] == \"CABG + PCI\")\n",
    "                                                                                                                                                    & (chd_inp_tr_by_fc[\"PTCOUNTY_NAME\"] == county)\n",
    "                                                                                                                                                    & (chd_inp_tr_by_fc[\"YEAR\"] == year), \"PROC_COUNT\"],\n",
    "                                                                                                                        chd_inp_tr_by_fc.loc[(chd_inp_tr_by_fc[\"PROCEDURE\"] == \"CABG\")\n",
    "                                                                                                                                                    & (chd_inp_tr_by_fc[\"PTCOUNTY_NAME\"] == county)\n",
    "                                                                                                                                                    & (chd_inp_tr_by_fc[\"YEAR\"] == year), \"PROC_COUNT\"])\n",
    "        chd_inp_tr_by_fc.loc[(chd_inp_tr_by_fc[\"PROCEDURE\"] == \"PCI\")\n",
    "                                    & (chd_inp_tr_by_fc[\"PTCOUNTY_NAME\"] == county)\n",
    "                                    & (chd_inp_tr_by_fc[\"YEAR\"] == year), \"PROC_COUNT\"] = sum(chd_inp_tr_by_fc.loc[(chd_inp_tr_by_fc[\"PROCEDURE\"] == \"CABG + PCI\")\n",
    "                                                                                                                                                    & (chd_inp_tr_by_fc[\"PTCOUNTY_NAME\"] == county)\n",
    "                                                                                                                                                    & (chd_inp_tr_by_fc[\"YEAR\"] == year), \"PROC_COUNT\"],\n",
    "                                                                                                                        chd_inp_tr_by_fc.loc[(chd_inp_tr_by_fc[\"PROCEDURE\"] == \"PCI\")\n",
    "                                                                                                                                                    & (chd_inp_tr_by_fc[\"PTCOUNTY_NAME\"] == county)\n",
    "                                                                                                                                                    & (chd_inp_tr_by_fc[\"YEAR\"] == year), \"PROC_COUNT\"])\n",
    "chd_inp_tr_by_fc = chd_inp_tr_by_fc[~((chd_inp_tr_by_fc[\"PROCEDURE\"] == \"CABG + PCI\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = chd_inp_tr_by_fc.groupby([\"PTCOUNTY_NAME\", \"FAC_COUNTY_NAME\", \"PROCEDURE\"]).agg(\n",
    "                                                            PROC_COUNT=pd.NamedAgg(column='PROC_COUNT', aggfunc='sum')\n",
    "                                                        ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_percentage_dict = {}\n",
    "counties = chd_inp_tr_by_fc[\"PTCOUNTY_NAME\"].unique()\n",
    "\n",
    "for county in counties:\n",
    "    max_percentage_dict[county] = {}  # Initialize a sub-dictionary for each county\n",
    "    fig, axes = plt.subplots(1, len(treatments[:-1]), figsize=(20, 6))  # Create a subplot for each treatment\n",
    "\n",
    "    for index, procedure in enumerate(treatments[:-1]):  # Iterate through treatments\n",
    "        records = chd_inp_tr_by_fc.loc[(chd_inp_tr_by_fc[\"PTCOUNTY_NAME\"] == county) & (chd_inp_tr_by_fc[\"PROCEDURE\"] == procedure)]\n",
    "        if not records.empty:\n",
    "            order = records.groupby(\"FAC_COUNTY_NAME\")['PROC_COUNT'].sum().sort_values(ascending=False).index\n",
    "            sns.barplot(data=records, x=\"FAC_COUNTY_NAME\", y=\"PROC_COUNT\", order=order, ax=ax)\n",
    "            \n",
    "            total = records['PROC_COUNT'].sum()\n",
    "            for p in ax.patches:\n",
    "                percentage = 100 * p.get_height() / total\n",
    "                x = p.get_x() + p.get_width() / 2\n",
    "                y = p.get_height()\n",
    "                ax.annotate(f'{percentage:.1f}%', (x, y), ha='center', va='bottom')\n",
    "\n",
    "            # storing each facility's percentage for this procedure in the nested dictionary\n",
    "            for facility in order:\n",
    "                facility_total = records[records['FAC_COUNTY_NAME'] == facility]['PROC_COUNT'].sum()\n",
    "                percentage = 100 * facility_total / total\n",
    "                max_percentage_dict[county][procedure][facility] = round(percentage, 2)\n",
    "\n",
    "        ax.set_title(f\"Percentage of {procedure} Treatment in {county}\")\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "        ax.set_xlabel(\"Facility County\")\n",
    "        ax.set_ylabel(\"Procedure Count\")\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chd_inp_tr_by_fc[chd_inp_tr_by_fc[\"PTCOUNTY_NAME\"] == \"Alachua\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_percentage_dict = {}\n",
    "counties = chd_inp_tr_by_fc[\"PTCOUNTY_NAME\"].unique()\n",
    "\n",
    "for county in counties:\n",
    "    max_percentage_dict[county] = {treatment: {} for treatment in treatments[:-1]}\n",
    "    num_treatments = len(treatments[:-1])\n",
    "    fig, axes = plt.subplots(1, num_treatments, figsize=(20, 6))\n",
    "\n",
    "    for index, procedure in enumerate(treatments[:-1]):\n",
    "        ax = axes[index] if num_treatments > 1 else axes\n",
    "        records = grouped[(grouped[\"PTCOUNTY_NAME\"] == county) & (grouped[\"PROCEDURE\"] == procedure)]\n",
    "        if not records.empty:\n",
    "            order = records.groupby(\"FAC_COUNTY_NAME\")['PROC_COUNT'].sum().sort_values(ascending=False).index\n",
    "            sns.barplot(data=records, x=\"FAC_COUNTY_NAME\", y=\"PROC_COUNT\", order=order, ax=ax)\n",
    "            \n",
    "            total = records['PROC_COUNT'].sum()\n",
    "            for p in ax.patches:\n",
    "                percentage = 100 * p.get_height() / total\n",
    "                x = p.get_x() + p.get_width() / 2\n",
    "                y = p.get_height()\n",
    "                ax.annotate(f'{percentage:.1f}%', (x, y), ha='center', va='bottom')\n",
    "\n",
    "            # storing each facility's percentage for this procedure in the nested dictionary\n",
    "            for facility in order:\n",
    "                facility_total = records[records['FAC_COUNTY_NAME'] == facility]['PROC_COUNT'].sum()\n",
    "                percentage = 100 * facility_total / total\n",
    "                max_percentage_dict[county][procedure][facility] = round(percentage, 2)\n",
    "\n",
    "        ax.set_title(f\"Percentage of {procedure} Treatment in {county}\")\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "        ax.set_xlabel(\"Facility County\")\n",
    "        ax.set_ylabel(\"Procedure Count\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the percentage of people travelling to different facility counties to get treated\n",
    "max_percentage_dict\n",
    "data_for_df = []\n",
    "\n",
    "for patient_county, procedures in max_percentage_dict.items():\n",
    "    for procedure, facility_counts in procedures.items():\n",
    "        data_for_df.append({\n",
    "            'PATIENT_COUNTY': patient_county,\n",
    "            'PROCEDURE': procedure,\n",
    "            'FACILITY_COUNTY_PERCENTAGES': facility_counts \n",
    "        })\n",
    "\n",
    "# convert the list to a DataFrame\n",
    "df = pd.DataFrame(data_for_df)\n",
    "\n",
    "# show the resulting DataFrame\n",
    "df.to_excel(\"ptcounty-to-fccounty.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_procedure_graph(df, procedure_name):\n",
    "    \"\"\"\n",
    "    Create network graph for the two treatments procedures seperately\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    for index, row in df.iterrows():\n",
    "        patient_county = row['PATIENT_COUNTY']\n",
    "        for facility_county, percentage in row['FACILITY_COUNTY_PERCENTAGES'].items():\n",
    "            if patient_county != facility_county:\n",
    "                G.add_edge(patient_county, facility_county, percentage=percentage)\n",
    "    \n",
    "    in_degrees = G.in_degree()\n",
    "    in_degree_dict = dict(in_degrees)\n",
    "    max_in_degree = max(in_degree_dict.values(), default=1)\n",
    "    node_sizes = [in_degree_dict.get(node, 0) * 100 for node in G.nodes()]\n",
    "    node_colors = [in_degree_dict[node] / max_in_degree for node in G.nodes()]\n",
    "\n",
    "    pos = nx.kamada_kawai_layout(G)\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    # Draw nodes and edges\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, cmap=plt.cm.viridis)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "    nx.draw_networkx_edges(G, pos, arrowstyle='->', arrowsize=10, edge_color='grey')\n",
    "\n",
    "    # Get the current axes and create colorbar\n",
    "    ax = plt.gca()\n",
    "    sm = plt.cm.ScalarMappable(cmap=plt.cm.viridis, norm=plt.Normalize(vmin=0, vmax=max_in_degree))\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax)\n",
    "    cbar.set_label('In-Degree')\n",
    "\n",
    "    plt.title(f'Patient Flow for {procedure_name} Procedures')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pci = df[df['PROCEDURE'] == 'PCI']\n",
    "df_cabg = df[df['PROCEDURE'] == 'CABG']\n",
    "\n",
    "create_procedure_graph(df_pci, 'CABG')\n",
    "#create_procedure_graph(df_cabg, 'CABG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting to the next 10 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sarima_model(model_config, data):\n",
    "    \"\"\"\n",
    "    Load the SARIMA configurations and fit the model\n",
    "    \"\"\"\n",
    "    model_config = model_config.strip()\n",
    "    config_order = re.match(r\"ARIMA\\((\\d+),(\\d+),(\\d+)\\)\\((\\d+),(\\d+),(\\d+)\\)\\[(\\d+)\\]\", model_config)\n",
    "    if config_order:\n",
    "        p, d, q = map(int, config_order.groups()[:3])\n",
    "        P, D, Q, s = map(int, config_order.groups()[3:])\n",
    "\n",
    "        model = auto_arima(data[:-4], error_action=\"ignore\", trace=False, suppress_warnings=True, maxiter=5, seasonal=True, stepwise=True)\n",
    "        return model\n",
    "\n",
    "def load_exponential_smoothing_model(model_config, data):\n",
    "    \"\"\"\n",
    "    Load the Exponential Smoothing configurations and fit the model\n",
    "    \"\"\"\n",
    "    model_config = ast.literal_eval(model_config)\n",
    "    model = ExponentialSmoothing(\n",
    "        data[:-4],\n",
    "        seasonal_periods=model_config.get('seasonal_periods'),\n",
    "        trend=model_config.get('trend'),\n",
    "        seasonal=model_config.get('seasonal'),\n",
    "        damped_trend=model_config.get('damped_trend', False)).fit(optimized=True, remove_bias=model_config.get('remove_bias', True))\n",
    "\n",
    "    return model   \n",
    "\n",
    "def predict_and_store(model, model_type, ptcounty, periods=42, start='2023Q3'):\n",
    "    \"\"\"\n",
    "    Predict 42 quaters which gives results until 2033 Quater 3\n",
    "    \"\"\"\n",
    "    # create a range of future quarters\n",
    "    future_quarters = pd.period_range(start=start, periods=periods, freq='Q')\n",
    "    \n",
    "    if model_type == \"SARIMA\":\n",
    "        predictions = model.predict(periods)\n",
    "    else:\n",
    "        predictions = model.forecast(periods)\n",
    "    # create a DataFrame with year-quarter as one column and the predictions as another\n",
    "    forecast_df = pd.DataFrame({\n",
    "        \"PTCOUNTY_NAME\":ptcounty,\n",
    "        'YEAR_QTR': future_quarters.strftime('%YQ%q'),\n",
    "        'DIAG_COUNT': predictions\n",
    "    })\n",
    "    return forecast_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the best model configuration files for treatments and diagnostics\n",
    "diag_model_config_df = pd.read_excel(\"diagnosis-model-configs.xlsx\")\n",
    "treatment_model_confg_df = pd.read_excel(\"treatments-model-configs.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and predict diagnostics\n",
    "forecasted_results_diag = pd.DataFrame()\n",
    "for county in counties:\n",
    "    mask = (chd_ed_diag_pt_by_age_agg[\"PTCOUNTY_NAME\"] == county)\n",
    "    data = chd_ed_diag_pt_by_age_agg[mask]\n",
    "    configs = diag_model_config_df.loc[(diag_model_config_df[\"County\"] == county), [\"BEST MODEL\", \"SARIMA\", \"EXPONENTIAL SMOOTHING\"]].iloc[0]\n",
    "    if configs[\"BEST MODEL\"] == \"SARIMA\":\n",
    "        model = load_sarima_model(configs[\"SARIMA\"], data[\"DIAG_COUNT\"])\n",
    "    else:\n",
    "        model = load_exponential_smoothing_model(configs[\"EXPONENTIAL SMOOTHING\"], data[\"DIAG_COUNT\"])\n",
    "    county_forecast = predict_and_store(model, configs[\"BEST MODEL\"], county, start='2023Q4')\n",
    "    forecasted_results_diag = pd.concat([forecasted_results_diag, county_forecast], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatanate both historical and predicted outputs into one\n",
    "forecasted_results_diag_ = pd.concat([forecasted_results_diag, chd_ed_diag_pt_by_age_agg[[\"PTCOUNTY_NAME\", \"YEAR_QTR\", \"DIAG_COUNT\"]]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and predict treatments\n",
    "forecasted_results_proc = pd.DataFrame()\n",
    "for county in counties:\n",
    "    for treatment in treatments[:-1]:\n",
    "        mask = (chd_inp_pt_by_age_agg[\"PTCOUNTY_NAME\"] == county) & (chd_inp_pt_by_age_agg[\"PROCEDURE\"] == treatment)\n",
    "        data = chd_inp_pt_by_age_agg[mask]\n",
    "        configs = treatment_model_confg_df.loc[(treatment_model_confg_df[\"County\"] == county), [\"BEST MODEL\", \"SARIMA\", \"EXPONENTIAL SMOOTHING\"]].iloc[0]\n",
    "        if configs[\"BEST MODEL\"] == \"SARIMA\":\n",
    "            model = load_sarima_model(configs[\"SARIMA\"], data[\"PROC_COUNT\"])\n",
    "        else:\n",
    "            model = load_exponential_smoothing_model(configs[\"EXPONENTIAL SMOOTHING\"], data[\"PROC_COUNT\"])\n",
    "        county_forecast = predict_and_store(model, configs[\"BEST MODEL\"], county, treatment, start='2023Q4')\n",
    "        forecasted_results_proc = pd.concat([forecasted_results_proc, county_forecast], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatanate both historical and predicted outputs into one\n",
    "forecasted_results_proc_ = pd.concat([forecasted_results_proc, chd_inp_pt_by_age_agg[[\"PTCOUNTY_NAME\", \"YEAR_QTR\", \"PROCEDURE\", \"PROC_COUNT\"]]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substring the year from the yqar quater\n",
    "forecasted_results_proc_[\"YEAR\"] = forecasted_results_proc_[\"YEAR_QTR\"].str.extract(r'(\\d{4})').astype(int)\n",
    "forecasted_results_diag_[\"YEAR\"] = forecasted_results_diag_[\"YEAR_QTR\"].str.extract(r'(\\d{4})').astype(int)\n",
    "\n",
    "# obtain the ceiling value from the predicted output.\n",
    "forecasted_results_proc_annual = forecasted_results_proc_.groupby(['PTCOUNTY_NAME', 'PROCEDURE', 'YEAR'])['PROC_COUNT'].sum().reset_index()\n",
    "forecasted_results_proc_annual[\"PROC_COUNT\"] = np.ceil(forecasted_results_proc_annual[\"PROC_COUNT\"])\n",
    "forecasted_results_diag_annual = forecasted_results_diag_.groupby(['PTCOUNTY_NAME', 'YEAR'])['DIAG_COUNT'].sum().reset_index()\n",
    "forecasted_results_diag_annual[\"DIAG_COUNT\"] = np.ceil(forecasted_results_diag_annual[\"DIAG_COUNT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasted_results_diag_annual.to_excel(\"CHD-Diagnostics-Predictions.xlsx\")\n",
    "forecasted_results_proc_annual.to_excel(\"CHD-Treatments-Predictions.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain predictions up until 2033. Because, after 2033 theres a steep drop in the predictions which indicates a possible overfitting scenario. \n",
    "filtered_diag_forecast = forecasted_results_diag_annual[(forecasted_results_diag_annual[\"YEAR\"] >= 2023)\n",
    "                                                        & (forecasted_results_diag_annual[\"YEAR\"] < 2034)]\n",
    "filtered_proc_forecast = forecasted_results_proc_annual[(forecasted_results_proc_annual[\"YEAR\"] >= 2023)\n",
    "                                                        & (forecasted_results_diag_annual[\"YEAR\"] < 2034)]\n",
    "\n",
    "# plot the predictions in a time series plot\n",
    "fig, axes = plt.subplots(nrows=len(counties), ncols=len(treatments), figsize=(30, 7 * len(counties)))\n",
    "\n",
    "for i, county in enumerate(counties):\n",
    "    county_data = filtered_diag_forecast[(filtered_diag_forecast[\"PTCOUNTY_NAME\"]==county)]\n",
    "    ax = axes[i][0] if len(counties) > 1 else axes[0]\n",
    "    ax.plot(county_data['YEAR'] , county_data['DIAG_COUNT'], marker='o', linestyle='-')\n",
    "    ax.set_title(f'Diagnosis Counts for {county}')\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.grid(True)\n",
    "    for j, procedure in enumerate(treatments[:-1]):\n",
    "        if procedure == \"PCI\":\n",
    "            div = 23\n",
    "        else:\n",
    "            div = 15\n",
    "        county_data = filtered_proc_forecast[(filtered_proc_forecast[\"PTCOUNTY_NAME\"]==county) & (filtered_proc_forecast[\"PROCEDURE\"]==procedure)]\n",
    "        ax = axes[i][j + 1] if len(counties) > 1 else axes[j + 1]\n",
    "        ax.plot(county_data['YEAR'], county_data['PROC_COUNT'], marker='o', linestyle='-', color=treatment_colors[procedure])\n",
    "        ax.set_title(f'{procedure} Counts for {county}')\n",
    "        ax.set_xlabel('Year')\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the percentage of people travelling to different counties for treatment.\n",
    "data = pd.read_excel(\"ptcounty-to-fccounty.xlsx\")\n",
    "data = data.drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming 'data' is your initial DataFrame loaded from an Excel file\n",
    "\n",
    "def expand_facility_county(row):\n",
    "    \"\"\"\n",
    "    this function will parse the 'Facility County %' column which contains string representations of dictionaries\n",
    "    \"\"\"\n",
    "    # Convert the string representation of a dictionary to an actual dictionary\n",
    "    facility_county_percentages = literal_eval(row['FACILITY_COUNTY_PERCENTAGES'])\n",
    "    # Create a list of tuples (Facility County, Percentage)\n",
    "    return [(facility, percentage) for facility, percentage in facility_county_percentages.items()]\n",
    "\n",
    "# apply the function to each row and store the result in a new 'expanded' column\n",
    "data['expanded'] = data.apply(expand_facility_county, axis=1)\n",
    "\n",
    "# now we create a new dataFrame to hold the expanded information\n",
    "expanded_data = []\n",
    "\n",
    "# iterate over the initial dataFrame\n",
    "for index, row in data.iterrows():\n",
    "    for facility, percentage in row['expanded']:\n",
    "        expanded_data.append({\n",
    "            'County': row['PATIENT_COUNTY'],\n",
    "            'Procedure': row['PATIENT_COUNTY'],\n",
    "            'Facility County': facility,\n",
    "            'Percentage': percentage\n",
    "        })\n",
    "\n",
    "expanded_df = pd.DataFrame(expanded_data)\n",
    "print(expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the exapanded dataframe to a new csv file.\n",
    "expanded_df.to_excel(\"ptcounty-to-fccounty-expanded.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kpmg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
